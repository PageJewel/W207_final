{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style\n",
    "matplotlib.style.use('ggplot')\n",
    "import seaborn\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# SK-Learn Libraries for feature tuning\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data shape:  (15120, 55)\n",
      "full label shape: (15120,)\n"
     ]
    }
   ],
   "source": [
    "# Load full training data set\n",
    "full_data = np.loadtxt(\"train.csv\", dtype = \"int\", delimiter = \",\", skiprows=1)\n",
    "feature_names = np.loadtxt(\"train.csv\", dtype = \"str\", delimiter = \",\")[0,:]\n",
    "\n",
    "# Split into data and labels\n",
    "full_data_labels = full_data[:,full_data.shape[1]-1]\n",
    "full_data = full_data[:,:full_data.shape[1]-1]\n",
    "\n",
    "print (\"full data shape: \", full_data.shape)\n",
    "print (\"full label shape:\", full_data_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define and Review Train/Dev Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train data shape:  (14120, 55)\n",
      "train label shape: (14120,)\n",
      "\n",
      "dev data shape:  (1000, 55)\n",
      "dev label shape: (1000,)\n",
      "\n",
      "Feature names are:\n",
      "[\"b'Id'\" \"b'Elevation'\" \"b'Aspect'\" \"b'Slope'\"\n",
      " \"b'Horizontal_Distance_To_Hydrology'\" \"b'Vertical_Distance_To_Hydrology'\"\n",
      " \"b'Horizontal_Distance_To_Roadways'\" \"b'Hillshade_9am'\"\n",
      " \"b'Hillshade_Noon'\" \"b'Hillshade_3pm'\"\n",
      " \"b'Horizontal_Distance_To_Fire_Points'\" \"b'Wilderness_Area1'\"\n",
      " \"b'Wilderness_Area2'\" \"b'Wilderness_Area3'\" \"b'Wilderness_Area4'\"\n",
      " \"b'Soil_Type1'\" \"b'Soil_Type2'\" \"b'Soil_Type3'\" \"b'Soil_Type4'\"\n",
      " \"b'Soil_Type5'\" \"b'Soil_Type6'\" \"b'Soil_Type7'\" \"b'Soil_Type8'\"\n",
      " \"b'Soil_Type9'\" \"b'Soil_Type10'\" \"b'Soil_Type11'\" \"b'Soil_Type12'\"\n",
      " \"b'Soil_Type13'\" \"b'Soil_Type14'\" \"b'Soil_Type15'\" \"b'Soil_Type16'\"\n",
      " \"b'Soil_Type17'\" \"b'Soil_Type18'\" \"b'Soil_Type19'\" \"b'Soil_Type20'\"\n",
      " \"b'Soil_Type21'\" \"b'Soil_Type22'\" \"b'Soil_Type23'\" \"b'Soil_Type24'\"\n",
      " \"b'Soil_Type25'\" \"b'Soil_Type26'\" \"b'Soil_Type27'\" \"b'Soil_Type28'\"\n",
      " \"b'Soil_Type29'\" \"b'Soil_Type30'\" \"b'Soil_Type31'\" \"b'Soil_Type32'\"\n",
      " \"b'Soil_Type33'\" \"b'Soil_Type34'\" \"b'Soil_Type35'\" \"b'Soil_Type36'\"\n",
      " \"b'Soil_Type37'\" \"b'Soil_Type38'\" \"b'Soil_Type39'\" \"b'Soil_Type40'\"\n",
      " \"b'Cover_Type'\"]\n",
      "\n",
      "An example row of training data:\n",
      "[1252 2801   60   27  335  122  361  229  172   59 1900    1    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Split into smaller training set and a dev set for us to use\n",
    "# Shuffle the input so that we get a random subset in training vs dev\n",
    "# Test set provided separately from kaggle where we do not know the labels\n",
    "np.random.seed(58230)\n",
    "shuffle = np.random.permutation(np.arange(full_data.shape[0]))\n",
    "full_data, full_data_labels = full_data[shuffle], full_data_labels[shuffle]\n",
    "\n",
    "train_data, train_labels = full_data[:14120], full_data_labels[:14120]\n",
    "dev_data, dev_labels = full_data[14120:], full_data_labels[14120:]\n",
    "\n",
    "print (\"\\ntrain data shape: \", train_data.shape)\n",
    "print (\"train label shape:\", train_labels.shape)\n",
    "print (\"\\ndev data shape: \", dev_data.shape)\n",
    "print (\"dev label shape:\", dev_labels.shape)\n",
    "\n",
    "\n",
    "# Print some basic info looking at a row of data\n",
    "print(\"\\nFeature names are:\")\n",
    "print(feature_names)\n",
    "\n",
    "print(\"\\nAn example row of training data:\")\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Scaling\n",
    "def my_scaler(data):    \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    continuous = scaler.fit_transform(data[:,:10])\n",
    "    binary = data[:,10:]\n",
    "    return np.concatenate((continuous, binary),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature selection\n",
    "def my_featureselection(num_features, fit_data, fit_labels, transform_data):\n",
    "    selection = SelectKBest(k=num_features)\n",
    "    top_train = selection.fit_transform(fit_data,fit_labels)\n",
    "    top_dev = selection.transform(transform_data)\n",
    "    return [top_train, top_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmakhani\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "C:\\Users\\mmakhani\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [21 22 29] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\mmakhani\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "scaled_train_data = my_scaler(train_data)\n",
    "scaled_dev_data = my_scaler(dev_data)\n",
    "top25_train_data,top25_dev_data = my_featureselection(25,train_data,train_labels,dev_data)\n",
    "top25_scaled_train_data,top25_scaled_dev_data = my_featureselection(25,scaled_train_data,train_labels,scaled_dev_data)\n",
    "scaled_top25_train_data = my_scaler(my_featureselection(25,train_data,train_labels,dev_data)[0])\n",
    "scaled_top25_dev_data = my_scaler(my_featureselection(25,train_data,train_labels,dev_data)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assess_model(model,train_data,train_labels,dev_data):\n",
    "    model = model\n",
    "    model.fit(train_data,train_labels)\n",
    "    dev_preds = model.predict(dev_data)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(dev_labels,dev_preds)\n",
    "    f1score = metrics.f1_score(dev_labels,dev_preds,average='weighted')\n",
    "    confusion = confusion_matrix(dev_labels,dev_preds) \n",
    "    report = classification_report(dev_labels,dev_preds)\n",
    "    \n",
    "    print('Accuracy: ', accuracy)\n",
    "    print('F1 Score: ', f1score)\n",
    "    print('Confusion Matrix: \\n', confusion)\n",
    "    print('Classification Report: \\n',report)\n",
    "    \n",
    "    return [accuracy,f1score,confusion,report]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K Nearest Neighbor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.82\n",
      "F1 Score:  0.815523351995\n",
      "Confusion Matrix: \n",
      " [[ 97  25   0   0   3   1  20]\n",
      " [ 23  67   5   0  10   6   2]\n",
      " [  0   1 123  19   1  13   0]\n",
      " [  0   0   3 127   0   4   0]\n",
      " [  0   2   7   0 133   2   0]\n",
      " [  0   2  18   6   4 126   0]\n",
      " [  3   0   0   0   0   0 147]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.66      0.72       146\n",
      "          2       0.69      0.59      0.64       113\n",
      "          3       0.79      0.78      0.79       157\n",
      "          4       0.84      0.95      0.89       134\n",
      "          5       0.88      0.92      0.90       144\n",
      "          6       0.83      0.81      0.82       156\n",
      "          7       0.87      0.98      0.92       150\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = assess_model(KNeighborsClassifier(),train_data,train_labels,dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.37\n",
      "F1 Score:  0.368345380673\n",
      "Confusion Matrix: \n",
      " [[54 33  6  6 17  5 25]\n",
      " [33 31  8  6 18  8  9]\n",
      " [10 16 55 25 11 39  1]\n",
      " [ 3  2 22 90  6 11  0]\n",
      " [22 26 13 18 50  8  7]\n",
      " [16  8 48 23 13 47  1]\n",
      " [49 29  7  1 17  4 43]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.29      0.37      0.32       146\n",
      "          2       0.21      0.27      0.24       113\n",
      "          3       0.35      0.35      0.35       157\n",
      "          4       0.53      0.67      0.59       134\n",
      "          5       0.38      0.35      0.36       144\n",
      "          6       0.39      0.30      0.34       156\n",
      "          7       0.50      0.29      0.36       150\n",
      "\n",
      "avg / total       0.38      0.37      0.37      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = assess_model(KNeighborsClassifier(),scaled_train_data,train_labels,scaled_dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.829\n",
      "F1 Score:  0.82498536594\n",
      "Confusion Matrix: \n",
      " [[102  23   0   0   4   1  16]\n",
      " [ 22  70   5   0   8   6   2]\n",
      " [  0   1 117  21   2  16   0]\n",
      " [  0   0   5 127   0   2   0]\n",
      " [  0   2   6   0 135   1   0]\n",
      " [  0   1  14   7   3 131   0]\n",
      " [  3   0   0   0   0   0 147]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.70      0.75       146\n",
      "          2       0.72      0.62      0.67       113\n",
      "          3       0.80      0.75      0.77       157\n",
      "          4       0.82      0.95      0.88       134\n",
      "          5       0.89      0.94      0.91       144\n",
      "          6       0.83      0.84      0.84       156\n",
      "          7       0.89      0.98      0.93       150\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = assess_model(KNeighborsClassifier(),top25_train_data,train_labels,top25_dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.795\n",
      "F1 Score:  0.791635918999\n",
      "Confusion Matrix: \n",
      " [[ 88  32   0   0  10   0  16]\n",
      " [ 16  77   4   1   8   5   2]\n",
      " [  0   4 106  10   4  33   0]\n",
      " [  0   0   3 127   0   4   0]\n",
      " [  1   8   5   0 126   4   0]\n",
      " [  0   3  22   5   2 124   0]\n",
      " [  3   0   0   0   0   0 147]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.60      0.69       146\n",
      "          2       0.62      0.68      0.65       113\n",
      "          3       0.76      0.68      0.71       157\n",
      "          4       0.89      0.95      0.92       134\n",
      "          5       0.84      0.88      0.86       144\n",
      "          6       0.73      0.79      0.76       156\n",
      "          7       0.89      0.98      0.93       150\n",
      "\n",
      "avg / total       0.80      0.80      0.79      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = assess_model(KNeighborsClassifier(),scaled_top25_train_data,train_labels,scaled_top25_dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.371\n",
      "F1 Score:  0.372629439163\n",
      "Confusion Matrix: \n",
      " [[46 40  8  3 15  6 28]\n",
      " [27 32 12  6 17  8 11]\n",
      " [13 13 54 31 12 34  0]\n",
      " [ 1  0 30 89  3 11  0]\n",
      " [27 27 15  8 54 12  1]\n",
      " [12 10 49 23 16 44  2]\n",
      " [58 20  8  1 10  1 52]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.32      0.28       146\n",
      "          2       0.23      0.28      0.25       113\n",
      "          3       0.31      0.34      0.32       157\n",
      "          4       0.55      0.66      0.60       134\n",
      "          5       0.43      0.38      0.40       144\n",
      "          6       0.38      0.28      0.32       156\n",
      "          7       0.55      0.35      0.43       150\n",
      "\n",
      "avg / total       0.39      0.37      0.37      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = assess_model(KNeighborsClassifier(),top25_scaled_train_data,train_labels,top25_scaled_dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'n_neighbors': [1,2,3,5,7,10,13,16,20,25],'weights':['uniform','distance']\n",
    "         ,'metric':['minkowski','canberra','braycurtis'], 'p':[2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'braycurtis', 'n_neighbors': 1}\n",
      "0.8509206798866855\n"
     ]
    }
   ],
   "source": [
    "params = {'n_neighbors': [1,2,5],'metric':['braycurtis']}\n",
    "\n",
    "model_search = GridSearchCV(KNeighborsClassifier(),param_grid=params)\n",
    "model_search.fit(train_data,train_labels)\n",
    "print(model_search.best_params_)\n",
    "print(model_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.872\n",
      "F1 Score:  0.871447820648\n",
      "Confusion Matrix: \n",
      " [[115  16   0   0   3   1  11]\n",
      " [ 13  88   4   0   2   5   1]\n",
      " [  0   1 133  11   0  12   0]\n",
      " [  0   0   2 127   0   5   0]\n",
      " [  0   6   3   0 133   2   0]\n",
      " [  0   2  17   4   2 131   0]\n",
      " [  4   1   0   0   0   0 145]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.79      0.83       146\n",
      "          2       0.77      0.78      0.78       113\n",
      "          3       0.84      0.85      0.84       157\n",
      "          4       0.89      0.95      0.92       134\n",
      "          5       0.95      0.92      0.94       144\n",
      "          6       0.84      0.84      0.84       156\n",
      "          7       0.92      0.97      0.94       150\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_final = KNeighborsClassifier(n_neighbors=1,metric='braycurtis')\n",
    "model_final_results = assess_model(model_final,train_data,train_labels,dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.817\n",
      "F1 Score:  0.817126613195\n",
      "Confusion Matrix: \n",
      " [[ 95  38   0   0   4   1   8]\n",
      " [ 24  74   5   0   5   5   0]\n",
      " [  2   6 127   7   1  14   0]\n",
      " [  0   0   5 127   0   2   0]\n",
      " [  2   5   2   0 133   1   1]\n",
      " [  1   4  28   4   1 118   0]\n",
      " [  6   1   0   0   0   0 143]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.65      0.69       146\n",
      "          2       0.58      0.65      0.61       113\n",
      "          3       0.76      0.81      0.78       157\n",
      "          4       0.92      0.95      0.93       134\n",
      "          5       0.92      0.92      0.92       144\n",
      "          6       0.84      0.76      0.79       156\n",
      "          7       0.94      0.95      0.95       150\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = assess_model(DecisionTreeClassifier(),train_data,train_labels,dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'criterion': ['gini','entropy'],'max_depth':[2,4,7,10,15,50]\n",
    "         ,'min_samples_split':[2,4,7,10,15],'max_features':[20,26]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy'}\n",
      "0.7822237960339944\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "params = {'criterion': ['entropy']}\n",
    "\n",
    "model_search = GridSearchCV(DecisionTreeClassifier(),param_grid=params)\n",
    "model_search.fit(train_data,train_labels)\n",
    "print(model_search.best_params_)\n",
    "print(model_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.806\n",
      "F1 Score:  0.805777887162\n",
      "Confusion Matrix: \n",
      " [[ 93  40   0   0   3   1   9]\n",
      " [ 28  68   5   0   8   4   0]\n",
      " [  2   4 126   7   1  17   0]\n",
      " [  0   0   4 127   0   3   0]\n",
      " [  2   8   2   0 131   1   0]\n",
      " [  1   5  28   5   1 116   0]\n",
      " [  4   1   0   0   0   0 145]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.64      0.67       146\n",
      "          2       0.54      0.60      0.57       113\n",
      "          3       0.76      0.80      0.78       157\n",
      "          4       0.91      0.95      0.93       134\n",
      "          5       0.91      0.91      0.91       144\n",
      "          6       0.82      0.74      0.78       156\n",
      "          7       0.94      0.97      0.95       150\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_final = DecisionTreeClassifier()\n",
    "model_final_results = assess_model(model_final,train_data,train_labels,dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to visualize decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth = 5)\n",
    "dtree.fit(train_data,train_labels)\n",
    "\n",
    "export_graphviz(dtree,out_file = 'graph.dot')\n",
    "#pydotplus.graph_from_dot_file('graph.dot').write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.855\n",
      "F1 Score:  0.854136795642\n",
      "Confusion Matrix: \n",
      " [[108  26   0   0   5   1   6]\n",
      " [ 18  81   6   0   5   3   0]\n",
      " [  0   2 132   8   1  14   0]\n",
      " [  0   0   3 129   0   2   0]\n",
      " [  1   8   0   0 133   2   0]\n",
      " [  1   0  25   3   3 124   0]\n",
      " [  2   0   0   0   0   0 148]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.74      0.78       146\n",
      "          2       0.69      0.72      0.70       113\n",
      "          3       0.80      0.84      0.82       157\n",
      "          4       0.92      0.96      0.94       134\n",
      "          5       0.90      0.92      0.91       144\n",
      "          6       0.85      0.79      0.82       156\n",
      "          7       0.96      0.99      0.97       150\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = assess_model(RandomForestClassifier(),train_data,train_labels,dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators': [250],'max_features':[5,10,15,20,25,30,40,50,55]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 10, 'n_estimators': 100}\n",
      "0.8638101983002833\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "params = {'n_estimators': [100],'max_features':[7,8,9,10,11,12]}\n",
    "\n",
    "model_search = GridSearchCV(RandomForestClassifier(),param_grid=params)\n",
    "model_search.fit(train_data,train_labels)\n",
    "print(model_search.best_params_)\n",
    "print(model_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.881\n",
      "F1 Score:  0.880256957883\n",
      "Confusion Matrix: \n",
      " [[111  26   0   0   3   0   6]\n",
      " [ 15  83   5   0   6   4   0]\n",
      " [  0   0 138   4   1  14   0]\n",
      " [  0   0   1 130   0   3   0]\n",
      " [  0   5   0   0 136   3   0]\n",
      " [  0   2  15   3   1 135   0]\n",
      " [  2   0   0   0   0   0 148]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.76      0.81       146\n",
      "          2       0.72      0.73      0.72       113\n",
      "          3       0.87      0.88      0.87       157\n",
      "          4       0.95      0.97      0.96       134\n",
      "          5       0.93      0.94      0.93       144\n",
      "          6       0.85      0.87      0.86       156\n",
      "          7       0.96      0.99      0.97       150\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_final = RandomForestClassifier(n_estimators=250,max_features=25)\n",
    "model_final_results = assess_model(model_final,train_data,train_labels,dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.882\n",
      "F1 Score:  0.881127584137\n",
      "Confusion Matrix: \n",
      " [[110  27   0   0   3   0   6]\n",
      " [ 17  82   5   0   5   4   0]\n",
      " [  0   0 137   4   2  14   0]\n",
      " [  0   0   1 130   0   3   0]\n",
      " [  0   4   0   0 137   3   0]\n",
      " [  0   2  13   2   1 138   0]\n",
      " [  2   0   0   0   0   0 148]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.75      0.80       146\n",
      "          2       0.71      0.73      0.72       113\n",
      "          3       0.88      0.87      0.88       157\n",
      "          4       0.96      0.97      0.96       134\n",
      "          5       0.93      0.95      0.94       144\n",
      "          6       0.85      0.88      0.87       156\n",
      "          7       0.96      0.99      0.97       150\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = assess_model(AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=250,max_features=25)),train_data,train_labels,dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore Commonly Erroneous Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=1,metric='braycurtis')\n",
    "knn_model.fit(train_data,train_labels)\n",
    "knn_dev_preds = knn_model.predict(dev_data)\n",
    "knn_errors_index = np.where(knn_dev_preds!=dev_labels)\n",
    "knn_errors_data = dev_data[knn_errors_index]\n",
    "knn_errors_labels = dev_labels[knn_errors_index]\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=250,max_features=25)\n",
    "rf_model.fit(train_data,train_labels)\n",
    "rf_dev_preds = rf_model.predict(dev_data)\n",
    "rf_errors_index = np.where(rf_dev_preds!=dev_labels)\n",
    "rf_errors_data = dev_data[rf_errors_index]\n",
    "rf_errors_labels = dev_labels[rf_errors_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "(1, 116)\n",
      "(52,)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(knn_errors_index).shape)\n",
    "print(np.asarray(rf_errors_index).shape)\n",
    "print(np.intersect1d(knn_errors_index,rf_errors_index).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 55)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data[np.intersect1d(knn_errors_index,rf_errors_index)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_labels[np.intersect1d(knn_errors_index,rf_errors_index)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-6aa7fd67a8d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_errors_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf_errors_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_errors_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf_errors_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "np.concatenate((dev_data[np.intersect1d(knn_errors_index,rf_errors_index)],dev_labels[np.intersect1d(knn_errors_index,rf_errors_index)]),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Misc Exploration and Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = np.corrcoef(np.transpose(train_data[:,1:14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_matrix = seaborn.heatmap(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in np.linspace(1,14,14):\n",
    "    print(i, ' - ', feature_names[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
