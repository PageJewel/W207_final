{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "",
  "signature": "sha256:ee04b4b07338957f6d89095b8bed4619bc87c24477fa95e7427a9017f65fea57"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Forest Cover Type: Naive Bayes Exploration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For this project, we are working on predicting the forest cover type among 7 classifications based on cartographic variables from the US Geological Survey and USFS for each 30 x 30 meter cell of forest.\n",
      "\n",
      "For more details, please see: https://www.kaggle.com/c/forest-cover-type-prediction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Import libraries**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This tells matplotlib not to try opening a new window for each plot.\n",
      "%matplotlib inline\n",
      "\n",
      "# General libraries.\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.style\n",
      "matplotlib.style.use('ggplot')\n",
      "\n",
      "# SK-learn libraries for learning.\n",
      "from sklearn import preprocessing\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier \n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "\n",
      "# SK-Learn Libraries for feature tuning\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "\n",
      "# SK-learn libraries for evaluation.\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import classification_report"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Load Data**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load full training data set\n",
      "full_data = np.loadtxt(\"train.csv\", dtype = \"int\", delimiter = \",\", skiprows=1)\n",
      "feature_names = np.loadtxt(\"train.csv\", dtype = \"str\", delimiter = \",\")[0,:]\n",
      "feature_names = np.delete(feature_names, [0,55]) # Remove ID and output variable to match data set\n",
      "\n",
      "# Split into data and labels\n",
      "full_data_labels = full_data[:,full_data.shape[1]-1]\n",
      "full_data = full_data[:,:full_data.shape[1]-1]\n",
      "full_data = np.delete(full_data, 0, 1)  # Delete id to prevent use as feature\n",
      "\n",
      "print (\"full data shape: \", full_data.shape)\n",
      "print (\"full label shape:\", full_data_labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "full data shape:  (15120, 54)\n",
        "full label shape: (15120,)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Define and Review Train/Dev Data**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Split into smaller training set and a dev set for us to use\n",
      "# Shuffle the input so that we get a random subset in training vs dev\n",
      "# Test set provided separately from kaggle where we do not know the labels\n",
      "np.random.seed(58230)\n",
      "shuffle = np.random.permutation(np.arange(full_data.shape[0]))\n",
      "full_data, full_data_labels = full_data[shuffle], full_data_labels[shuffle]\n",
      "\n",
      "train_data, train_labels = full_data[:14120], full_data_labels[:14120]\n",
      "dev_data, dev_labels = full_data[14120:], full_data_labels[14120:]\n",
      "\n",
      "print (\"\\ntrain data shape: \", train_data.shape)\n",
      "print (\"train label shape:\", train_labels.shape)\n",
      "print (\"\\ndev data shape: \", dev_data.shape)\n",
      "print (\"dev label shape:\", dev_labels.shape)\n",
      "\n",
      "\n",
      "# Print some basic info looking at a row of data\n",
      "print(\"\\nFeature names are:\")\n",
      "print(feature_names)\n",
      "\n",
      "print(\"\\nAn example row of training data:\")\n",
      "print(train_data[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train data shape:  (14120, 54)\n",
        "train label shape: (14120,)\n",
        "\n",
        "dev data shape:  (1000, 54)\n",
        "dev label shape: (1000,)\n",
        "\n",
        "Feature names are:\n",
        "['Elevation' 'Aspect' 'Slope' 'Horizontal_Distance_To_Hydrology'\n",
        " 'Vertical_Distance_To_Hydrology' 'Horizontal_Distance_To_Roadways'\n",
        " 'Hillshade_9am' 'Hillshade_Noon' 'Hillshade_3pm'\n",
        " 'Horizontal_Distance_To_Fire_Points' 'Wilderness_Area1'\n",
        " 'Wilderness_Area2' 'Wilderness_Area3' 'Wilderness_Area4' 'Soil_Type1'\n",
        " 'Soil_Type2' 'Soil_Type3' 'Soil_Type4' 'Soil_Type5' 'Soil_Type6'\n",
        " 'Soil_Type7' 'Soil_Type8' 'Soil_Type9' 'Soil_Type10' 'Soil_Type11'\n",
        " 'Soil_Type12' 'Soil_Type13' 'Soil_Type14' 'Soil_Type15' 'Soil_Type16'\n",
        " 'Soil_Type17' 'Soil_Type18' 'Soil_Type19' 'Soil_Type20' 'Soil_Type21'\n",
        " 'Soil_Type22' 'Soil_Type23' 'Soil_Type24' 'Soil_Type25' 'Soil_Type26'\n",
        " 'Soil_Type27' 'Soil_Type28' 'Soil_Type29' 'Soil_Type30' 'Soil_Type31'\n",
        " 'Soil_Type32' 'Soil_Type33' 'Soil_Type34' 'Soil_Type35' 'Soil_Type36'\n",
        " 'Soil_Type37' 'Soil_Type38' 'Soil_Type39' 'Soil_Type40']\n",
        "\n",
        "An example row of training data:\n",
        "[2801   60   27  335  122  361  229  172   59 1900    1    0    0    0\n",
        "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
        "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
        "    1    0    0    0    0    0    0    0    0    0    0    0]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Preprocessing**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Confirm features with 0 variation\n",
      "print(\"For feature %s there are %d unique values in the training data\" % (feature_names[20], np.unique(train_data[:,20]).shape[0]))\n",
      "print(\"For feature %s there are %d unique values in the training data\" % (feature_names[21], np.unique(train_data[:,21]).shape[0]))\n",
      "print(\"For feature %s there are %d unique values in the training data\" % (feature_names[28], np.unique(train_data[:,28]).shape[0]))\n",
      "\n",
      "# Remove those features - Note: only run this section once\n",
      "train_data = np.delete(train_data, [20,21,28], 1)\n",
      "print (\"\\ntrain data shape: \", train_data.shape)\n",
      "\n",
      "dev_data = np.delete(dev_data, [20,21,28], 1)\n",
      "print (\"\\ndev data shape: \", dev_data.shape)\n",
      "\n",
      "feature_names = np.delete(feature_names, [20,21,28])\n",
      "print(\"\\nFeature names are:\")\n",
      "print(feature_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For feature Soil_Type7 there are 1 unique values in the training data\n",
        "For feature Soil_Type8 there are 1 unique values in the training data\n",
        "For feature Soil_Type15 there are 1 unique values in the training data\n",
        "\n",
        "train data shape:  (14120, 51)\n",
        "\n",
        "dev data shape:  (1000, 51)\n",
        "\n",
        "Feature names are:\n",
        "['Elevation' 'Aspect' 'Slope' 'Horizontal_Distance_To_Hydrology'\n",
        " 'Vertical_Distance_To_Hydrology' 'Horizontal_Distance_To_Roadways'\n",
        " 'Hillshade_9am' 'Hillshade_Noon' 'Hillshade_3pm'\n",
        " 'Horizontal_Distance_To_Fire_Points' 'Wilderness_Area1'\n",
        " 'Wilderness_Area2' 'Wilderness_Area3' 'Wilderness_Area4' 'Soil_Type1'\n",
        " 'Soil_Type2' 'Soil_Type3' 'Soil_Type4' 'Soil_Type5' 'Soil_Type6'\n",
        " 'Soil_Type9' 'Soil_Type10' 'Soil_Type11' 'Soil_Type12' 'Soil_Type13'\n",
        " 'Soil_Type14' 'Soil_Type16' 'Soil_Type17' 'Soil_Type18' 'Soil_Type19'\n",
        " 'Soil_Type20' 'Soil_Type21' 'Soil_Type22' 'Soil_Type23' 'Soil_Type24'\n",
        " 'Soil_Type25' 'Soil_Type26' 'Soil_Type27' 'Soil_Type28' 'Soil_Type29'\n",
        " 'Soil_Type30' 'Soil_Type31' 'Soil_Type32' 'Soil_Type33' 'Soil_Type34'\n",
        " 'Soil_Type35' 'Soil_Type36' 'Soil_Type37' 'Soil_Type38' 'Soil_Type39'\n",
        " 'Soil_Type40']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Scaling\n",
      "def my_scaler(data):    \n",
      "    scaler = preprocessing.StandardScaler()\n",
      "    continuous = scaler.fit_transform(data[:,:10])\n",
      "    binary = data[:,10:]\n",
      "    return np.concatenate((continuous, binary),axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Feature selection\n",
      "def my_featureselection(num_features, fit_data, fit_labels, transform_data):\n",
      "    selection = SelectKBest(k=num_features)\n",
      "    top_train = selection.fit_transform(fit_data,fit_labels)\n",
      "    top_dev = selection.transform(transform_data)\n",
      "    return [top_train, top_dev]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set up scaling of all original data, top 25 variables only, top 25 variables of scaled data, and scaling of top 25 variables\n",
      "scaled_train_data = my_scaler(train_data)\n",
      "scaled_dev_data = my_scaler(dev_data)\n",
      "top25_train_data,top25_dev_data = my_featureselection(25,train_data,train_labels,dev_data)\n",
      "top25_scaled_train_data,top25_scaled_dev_data = my_featureselection(25,scaled_train_data,train_labels,scaled_dev_data)\n",
      "scaled_top25_train_data = my_scaler(my_featureselection(25,train_data,train_labels,dev_data)[0])\n",
      "scaled_top25_dev_data = my_scaler(my_featureselection(25,train_data,train_labels,dev_data)[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/__init__.py:127: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
        "  if np.issubdtype(mask.dtype, np.int):\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define Model Assessment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def assess_model(model,train_data,train_labels,dev_data, replace_sigma=0, sigma_value1=0, sigma_value2=0):\n",
      "    model = model\n",
      "    model.fit(train_data,train_labels)\n",
      "    \n",
      "    if replace_sigma==1:       \n",
      "        # Set up new sigma array\n",
      "        new_sigma = model.sigma_\n",
      "        \n",
      "        # For each binary feature, reset its sigma value to the quantity provided\n",
      "        for i in range(train_data.shape[1]):\n",
      "            if np.unique(train_data[:,i]).shape[0]==2:\n",
      "                new_sigma[:,i] = sigma_value1\n",
      "        \n",
      "        # Replace sigma array for the model\n",
      "        model.sigma_ = new_sigma\n",
      "        \n",
      "    if replace_sigma==2:       \n",
      "        # Set up new sigma array\n",
      "        new_sigma = model.sigma_\n",
      "        \n",
      "        # For the multinomial feature, reset their sigma value to the quantity provided\n",
      "        # Assumes no other features have the same number of unique values. Confirmed this for initial continuous variables\n",
      "        # Takes first value provided for wilderness area, second for soil type\n",
      "        for i in range(train_data.shape[1]):\n",
      "            if np.unique(train_data[:,i]).shape[0]==4:\n",
      "                new_sigma[:,i] = sigma_value1\n",
      "            if np.unique(train_data[:,i]).shape[0]==37:\n",
      "                new_sigma[:,i] = sigma_value2\n",
      "        \n",
      "        # Replace sigma array for the model\n",
      "        model.sigma_ = new_sigma\n",
      "        \n",
      "    dev_preds = model.predict(dev_data)\n",
      "    \n",
      "    accuracy = metrics.accuracy_score(dev_labels,dev_preds)\n",
      "    f1score = metrics.f1_score(dev_labels,dev_preds,average='weighted')\n",
      "    confusion = confusion_matrix(dev_labels,dev_preds) \n",
      "    report = classification_report(dev_labels,dev_preds)\n",
      "    \n",
      "    print('Accuracy: ', accuracy)\n",
      "    print('F1 Score: ', f1score)\n",
      "    print('Confusion Matrix: \\n', confusion)\n",
      "    print('Classification Report: \\n',report)\n",
      "    \n",
      "    return [accuracy,f1score,confusion,report]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Best Naive Bayes**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our best NB had an accuracy of 0.664. It takes the top 25 variables, does not scale the data, and updates the sigma values of the binary variables to the standard deviation across all binary variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate standard deviation of all binary features in training data (regardless of which are in the model)\n",
      "# This is across all observations / classes\n",
      "sd_data = np.std(train_data[:,10:])\n",
      "\n",
      "# Create model for use later\n",
      "model_NB = GaussianNB()\n",
      "model_NB.fit(top25_train_data,train_labels)\n",
      "   \n",
      "# Set up new sigma array\n",
      "new_sigma = model_NB.sigma_\n",
      "        \n",
      "# For each binary feature, reset its sigma value to the quantity provided\n",
      "for i in range(top25_train_data.shape[1]):\n",
      "    if np.unique(top25_train_data[:,i]).shape[0]==2:\n",
      "        new_sigma[:,i] = sd_data\n",
      "        \n",
      "# Replace sigma array for the model\n",
      "model_NB.sigma_ = new_sigma\n",
      "\n",
      "# Get results for model\n",
      "model_results = assess_model(GaussianNB(),top25_train_data,train_labels,top25_dev_data,1,sd_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.664\n",
        "Accuracy: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.664\n",
        "F1 Score:  0.6490972408908385\n",
        "Confusion Matrix: \n",
        " [[ 80  24   2   0  11   1  28]\n",
        " [ 30  46   2   0  25   8   2]\n",
        " [  0   3  67  22  21  44   0]\n",
        " [  0   0   3 124   0   7   0]\n",
        " [  1   9   0   0 125   9   0]\n",
        " [  0   0  32  25  18  81   0]\n",
        " [  9   0   0   0   0   0 141]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.67      0.55      0.60       146\n",
        "          2       0.56      0.41      0.47       113\n",
        "          3       0.63      0.43      0.51       157\n",
        "          4       0.73      0.93      0.81       134\n",
        "          5       0.62      0.87      0.73       144\n",
        "          6       0.54      0.52      0.53       156\n",
        "          7       0.82      0.94      0.88       150\n",
        "\n",
        "avg / total       0.66      0.66      0.65      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Logistic Regression**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Had to switch solver from Beth's file. Also ran a simpler one than the best (I believe the best had accuracy of around 0.74)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the model for use later\n",
      "model_MN = LogisticRegression(C=3, class_weight='balanced',multi_class='multinomial',solver='lbfgs',max_iter=250)\n",
      "model_MN.fit(scaled_train_data, train_labels)\n",
      "\n",
      "# Get results for model\n",
      "model_results = assess_model(LogisticRegression(C=3, class_weight='balanced',multi_class='multinomial',solver='lbfgs',max_iter=250),\n",
      "                             scaled_train_data,train_labels,scaled_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.715\n",
        "F1 Score:  0.7104983952311604\n",
        "Confusion Matrix: \n",
        " [[100  26   0   0   5   1  14]\n",
        " [ 22  61   4   0  19   6   1]\n",
        " [  0   1  72  14   8  62   0]\n",
        " [  0   0   6 121   0   7   0]\n",
        " [  1  17   2   0 119   5   0]\n",
        " [  0   2  32  14   3 105   0]\n",
        " [ 13   0   0   0   0   0 137]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.74      0.68      0.71       146\n",
        "          2       0.57      0.54      0.55       113\n",
        "          3       0.62      0.46      0.53       157\n",
        "          4       0.81      0.90      0.86       134\n",
        "          5       0.77      0.83      0.80       144\n",
        "          6       0.56      0.67      0.61       156\n",
        "          7       0.90      0.91      0.91       150\n",
        "\n",
        "avg / total       0.71      0.71      0.71      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Best KNN**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Took from Forest_Cover_MM.ipynb the Best K Nearest Neighbor model, but changing to 3 neighbors in order to output probabilities. Mursil had accuracy of 0.872, while I only get 0.831 due to increasing number of neighbors and because Mursil still included the ID column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the model for use later\n",
      "model_knn = KNeighborsClassifier(n_neighbors=3,metric='braycurtis')\n",
      "model_knn.fit(train_data, train_labels)\n",
      "\n",
      "# Get results for model\n",
      "model_results = assess_model(KNeighborsClassifier(n_neighbors=3,metric='braycurtis'),train_data,train_labels,dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.831\n",
        "F1 Score:  0.8267592553933027\n",
        "Confusion Matrix: \n",
        " [[ 98  25   0   0   7   0  16]\n",
        " [ 21  67   6   0  14   5   0]\n",
        " [  0   1 125  13   2  16   0]\n",
        " [  0   0   1 129   0   4   0]\n",
        " [  0   5   1   0 136   2   0]\n",
        " [  0   2  17   4   3 130   0]\n",
        " [  4   0   0   0   0   0 146]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.80      0.67      0.73       146\n",
        "          2       0.67      0.59      0.63       113\n",
        "          3       0.83      0.80      0.81       157\n",
        "          4       0.88      0.96      0.92       134\n",
        "          5       0.84      0.94      0.89       144\n",
        "          6       0.83      0.83      0.83       156\n",
        "          7       0.90      0.97      0.94       150\n",
        "\n",
        "avg / total       0.83      0.83      0.83      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Ensemble - including predicted probabilities**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Taking computed probabilities from prior models and incoporating them into a RF in various combinations. Taking the parameters from the best RF from Mursil's Forest_cover_MM.ipynb which had accuracy of 0.881 (same set of parameters on original training data only had accuracy of 0.878 here, likely because no ID column).\n",
      "\n",
      "Found that none of the versions including predicted probabilities from other models outperformed the initial random forest. The closest included the original data, probabilities from NB and logistic regression, and had an accuracy of 0.873."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create new data sets for predicted probabilities for each class from the various models above\n",
      "# Will be used in various combinations for RF below\n",
      "\n",
      "predict_NB_train = model_NB.predict_proba(top25_train_data)\n",
      "predict_NB_dev = model_NB.predict_proba(top25_dev_data)\n",
      "predict_MN_train = model_MN.predict_proba(scaled_train_data)\n",
      "predict_MN_dev = model_MN.predict_proba(scaled_dev_data)\n",
      "predict_knn_train = model_knn.predict_proba(train_data)\n",
      "predict_knn_dev = model_knn.predict_proba(dev_data)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_results = assess_model(RandomForestClassifier(n_estimators=250,max_features=25),train_data,train_labels,dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.878\n",
        "F1 Score:  0.8766191095719107\n",
        "Confusion Matrix: \n",
        " [[108  28   0   0   3   0   7]\n",
        " [ 15  82   6   0   8   2   0]\n",
        " [  0   0 132   5   2  18   0]\n",
        " [  0   0   1 132   0   1   0]\n",
        " [  0   4   1   0 136   3   0]\n",
        " [  0   1  13   2   1 139   0]\n",
        " [  1   0   0   0   0   0 149]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.87      0.74      0.80       146\n",
        "          2       0.71      0.73      0.72       113\n",
        "          3       0.86      0.84      0.85       157\n",
        "          4       0.95      0.99      0.97       134\n",
        "          5       0.91      0.94      0.93       144\n",
        "          6       0.85      0.89      0.87       156\n",
        "          7       0.96      0.99      0.97       150\n",
        "\n",
        "avg / total       0.88      0.88      0.88      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "new_train_data = np.hstack((train_data, predict_NB_train, predict_MN_train, predict_knn_train))\n",
      "new_dev_data = np.hstack((dev_data, predict_NB_dev, predict_MN_dev, predict_knn_dev))\n",
      "model_results = assess_model(RandomForestClassifier(n_estimators=250,max_features=25),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.85\n",
        "F1 Score:  0.8500322307761623\n",
        "Confusion Matrix: \n",
        " [[107  30   0   0   4   0   5]\n",
        " [ 23  74   5   0   6   5   0]\n",
        " [  0   2 135   5   2  13   0]\n",
        " [  0   0   2 127   0   5   0]\n",
        " [  0   8   0   0 134   2   0]\n",
        " [  0   5  17   3   2 129   0]\n",
        " [  6   0   0   0   0   0 144]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.79      0.73      0.76       146\n",
        "          2       0.62      0.65      0.64       113\n",
        "          3       0.85      0.86      0.85       157\n",
        "          4       0.94      0.95      0.94       134\n",
        "          5       0.91      0.93      0.92       144\n",
        "          6       0.84      0.83      0.83       156\n",
        "          7       0.97      0.96      0.96       150\n",
        "\n",
        "avg / total       0.85      0.85      0.85      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "new_train_data = np.hstack((train_data, predict_MN_train, predict_knn_train))\n",
      "new_dev_data = np.hstack((dev_data, predict_MN_dev, predict_knn_dev))\n",
      "model_results = assess_model(RandomForestClassifier(n_estimators=250,max_features=25),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.849\n",
        "F1 Score:  0.8491058130750453\n",
        "Confusion Matrix: \n",
        " [[107  30   0   0   4   0   5]\n",
        " [ 22  75   5   0   6   5   0]\n",
        " [  0   3 133   5   2  14   0]\n",
        " [  0   0   3 126   0   5   0]\n",
        " [  0   7   0   0 135   2   0]\n",
        " [  0   5  17   3   2 129   0]\n",
        " [  6   0   0   0   0   0 144]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.79      0.73      0.76       146\n",
        "          2       0.62      0.66      0.64       113\n",
        "          3       0.84      0.85      0.84       157\n",
        "          4       0.94      0.94      0.94       134\n",
        "          5       0.91      0.94      0.92       144\n",
        "          6       0.83      0.83      0.83       156\n",
        "          7       0.97      0.96      0.96       150\n",
        "\n",
        "avg / total       0.85      0.85      0.85      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "new_train_data = np.hstack((train_data, predict_NB_train, predict_knn_train))\n",
      "new_dev_data = np.hstack((dev_data, predict_NB_dev, predict_knn_dev))\n",
      "model_results = assess_model(RandomForestClassifier(n_estimators=250,max_features=25),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.846\n",
        "F1 Score:  0.8468821318963714\n",
        "Confusion Matrix: \n",
        " [[107  30   0   0   4   0   5]\n",
        " [ 20  76   6   0   6   5   0]\n",
        " [  0   3 134   5   2  13   0]\n",
        " [  0   0   5 124   0   5   0]\n",
        " [  0  12   0   0 130   2   0]\n",
        " [  0   4  16   3   2 131   0]\n",
        " [  6   0   0   0   0   0 144]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.80      0.73      0.77       146\n",
        "          2       0.61      0.67      0.64       113\n",
        "          3       0.83      0.85      0.84       157\n",
        "          4       0.94      0.93      0.93       134\n",
        "          5       0.90      0.90      0.90       144\n",
        "          6       0.84      0.84      0.84       156\n",
        "          7       0.97      0.96      0.96       150\n",
        "\n",
        "avg / total       0.85      0.85      0.85      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "new_train_data = np.hstack((train_data, predict_NB_train, predict_MN_train))\n",
      "new_dev_data = np.hstack((dev_data, predict_NB_dev, predict_MN_dev))\n",
      "model_results = assess_model(RandomForestClassifier(n_estimators=250,max_features=25),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.873\n",
        "F1 Score:  0.8718048869487484\n",
        "Confusion Matrix: \n",
        " [[115  24   0   0   4   0   3]\n",
        " [ 19  76   6   0   9   3   0]\n",
        " [  0   1 129   4   1  22   0]\n",
        " [  0   0   0 132   0   2   0]\n",
        " [  0   3   2   0 137   2   0]\n",
        " [  0   3  12   3   0 138   0]\n",
        " [  4   0   0   0   0   0 146]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.83      0.79      0.81       146\n",
        "          2       0.71      0.67      0.69       113\n",
        "          3       0.87      0.82      0.84       157\n",
        "          4       0.95      0.99      0.97       134\n",
        "          5       0.91      0.95      0.93       144\n",
        "          6       0.83      0.88      0.85       156\n",
        "          7       0.98      0.97      0.98       150\n",
        "\n",
        "avg / total       0.87      0.87      0.87      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "# Remove max features parameter\n",
      "new_train_data = np.hstack((train_data, predict_NB_train, predict_MN_train))\n",
      "new_dev_data = np.hstack((dev_data, predict_NB_dev, predict_MN_dev))\n",
      "\n",
      "model_results = assess_model(AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=250,max_features=25)),\n",
      "                             new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.865\n",
        "F1 Score:  0.8642083826484508\n",
        "Confusion Matrix: \n",
        " [[112  25   0   0   4   0   5]\n",
        " [ 17  79   6   0   8   3   0]\n",
        " [  0   1 126   4   1  25   0]\n",
        " [  0   0   0 133   0   1   0]\n",
        " [  0   6   2   0 133   3   0]\n",
        " [  0   2  14   3   0 137   0]\n",
        " [  5   0   0   0   0   0 145]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.84      0.77      0.80       146\n",
        "          2       0.70      0.70      0.70       113\n",
        "          3       0.85      0.80      0.83       157\n",
        "          4       0.95      0.99      0.97       134\n",
        "          5       0.91      0.92      0.92       144\n",
        "          6       0.81      0.88      0.84       156\n",
        "          7       0.97      0.97      0.97       150\n",
        "\n",
        "avg / total       0.86      0.86      0.86      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "new_train_data = np.hstack((train_data, predict_knn_train))\n",
      "new_dev_data = np.hstack((dev_data, predict_knn_dev))\n",
      "model_results = assess_model(RandomForestClassifier(n_estimators=250,max_features=25),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.845\n",
        "F1 Score:  0.8456852986985932\n",
        "Confusion Matrix: \n",
        " [[103  33   0   0   4   0   6]\n",
        " [ 22  74   6   0   6   5   0]\n",
        " [  0   3 135   5   2  12   0]\n",
        " [  0   0   4 125   0   5   0]\n",
        " [  0  10   1   0 131   2   0]\n",
        " [  0   5  15   1   2 133   0]\n",
        " [  6   0   0   0   0   0 144]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.79      0.71      0.74       146\n",
        "          2       0.59      0.65      0.62       113\n",
        "          3       0.84      0.86      0.85       157\n",
        "          4       0.95      0.93      0.94       134\n",
        "          5       0.90      0.91      0.91       144\n",
        "          6       0.85      0.85      0.85       156\n",
        "          7       0.96      0.96      0.96       150\n",
        "\n",
        "avg / total       0.85      0.84      0.85      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "new_train_data = np.hstack((train_data, predict_MN_train))\n",
      "new_dev_data = np.hstack((dev_data, predict_MN_dev))\n",
      "model_results = assess_model(RandomForestClassifier(n_estimators=250,max_features=25),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.863\n",
        "F1 Score:  0.8622424636745827\n",
        "Confusion Matrix: \n",
        " [[111  27   0   0   4   0   4]\n",
        " [ 18  76   6   0   9   3   1]\n",
        " [  0   0 129   4   0  24   0]\n",
        " [  0   0   1 130   0   3   0]\n",
        " [  0   6   2   0 133   3   0]\n",
        " [  0   2  14   2   0 138   0]\n",
        " [  4   0   0   0   0   0 146]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.83      0.76      0.80       146\n",
        "          2       0.68      0.67      0.68       113\n",
        "          3       0.85      0.82      0.83       157\n",
        "          4       0.96      0.97      0.96       134\n",
        "          5       0.91      0.92      0.92       144\n",
        "          6       0.81      0.88      0.84       156\n",
        "          7       0.97      0.97      0.97       150\n",
        "\n",
        "avg / total       0.86      0.86      0.86      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "new_train_data = np.hstack((train_data, predict_NB_train))\n",
      "new_dev_data = np.hstack((dev_data, predict_NB_dev))\n",
      "model_results = assess_model(RandomForestClassifier(n_estimators=250,max_features=25),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.87\n",
        "F1 Score:  0.8686130768994239\n",
        "Confusion Matrix: \n",
        " [[107  28   0   0   3   1   7]\n",
        " [ 16  80   6   0   8   3   0]\n",
        " [  0   2 129   4   1  21   0]\n",
        " [  0   0   1 130   0   3   0]\n",
        " [  0   3   0   0 138   3   0]\n",
        " [  0   1  12   4   1 138   0]\n",
        " [  2   0   0   0   0   0 148]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.86      0.73      0.79       146\n",
        "          2       0.70      0.71      0.70       113\n",
        "          3       0.87      0.82      0.85       157\n",
        "          4       0.94      0.97      0.96       134\n",
        "          5       0.91      0.96      0.94       144\n",
        "          6       0.82      0.88      0.85       156\n",
        "          7       0.95      0.99      0.97       150\n",
        "\n",
        "avg / total       0.87      0.87      0.87      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "# had to remove max features b/c smaller data set to begin with\n",
      "new_train_data = np.hstack((predict_NB_train, predict_MN_train, predict_knn_train))\n",
      "new_dev_data = np.hstack((predict_NB_dev, predict_MN_dev, predict_knn_dev))\n",
      "model_results = assess_model(RandomForestClassifier(n_estimators=250),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.854\n",
        "F1 Score:  0.8538611279541316\n",
        "Confusion Matrix: \n",
        " [[104  32   0   0   4   0   6]\n",
        " [ 16  81   5   0   6   5   0]\n",
        " [  0   0 133   6   2  16   0]\n",
        " [  0   0   0 130   0   4   0]\n",
        " [  0   8   0   0 134   2   0]\n",
        " [  0   5  18   3   2 128   0]\n",
        " [  6   0   0   0   0   0 144]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.83      0.71      0.76       146\n",
        "          2       0.64      0.72      0.68       113\n",
        "          3       0.85      0.85      0.85       157\n",
        "          4       0.94      0.97      0.95       134\n",
        "          5       0.91      0.93      0.92       144\n",
        "          6       0.83      0.82      0.82       156\n",
        "          7       0.96      0.96      0.96       150\n",
        "\n",
        "avg / total       0.86      0.85      0.85      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Best Random Forest on all predicted probabilities\n",
      "new_train_data = np.hstack((predict_NB_train, predict_MN_train))\n",
      "new_dev_data = np.hstack((predict_NB_dev, predict_MN_dev))\n",
      "model_results = assess_model(RandomForestClassifier(n_estimators=250),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.804\n",
        "F1 Score:  0.8011649226964945\n",
        "Confusion Matrix: \n",
        " [[104  27   0   0   4   1  10]\n",
        " [ 19  76   5   0   9   4   0]\n",
        " [  0   1  98  12   1  45   0]\n",
        " [  0   0   5 128   0   1   0]\n",
        " [  0   4   2   0 134   4   0]\n",
        " [  0   2  25   9   2 118   0]\n",
        " [  4   0   0   0   0   0 146]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.82      0.71      0.76       146\n",
        "          2       0.69      0.67      0.68       113\n",
        "          3       0.73      0.62      0.67       157\n",
        "          4       0.86      0.96      0.90       134\n",
        "          5       0.89      0.93      0.91       144\n",
        "          6       0.68      0.76      0.72       156\n",
        "          7       0.94      0.97      0.95       150\n",
        "\n",
        "avg / total       0.80      0.80      0.80      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 48
    }
   ],
   "metadata": {}
  }
 ]
}