{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "",
  "signature": "sha256:dd5cff75983a0564eff69aceba26c3c4dcafa47d9cd712d24bb7a0799f0cfeac"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Forest Cover Type: Naive Bayes Exploration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For this project, we are working on predicting the forest cover type among 7 classifications based on cartographic variables from the US Geological Survey and USFS for each 30 x 30 meter cell of forest.\n",
      "\n",
      "For more details, please see: https://www.kaggle.com/c/forest-cover-type-prediction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Import libraries**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This tells matplotlib not to try opening a new window for each plot.\n",
      "%matplotlib inline\n",
      "\n",
      "# General libraries.\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.style\n",
      "matplotlib.style.use('ggplot')\n",
      "\n",
      "# SK-learn libraries for learning.\n",
      "from sklearn import preprocessing\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier \n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "\n",
      "# SK-Learn Libraries for feature tuning\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "\n",
      "# SK-learn libraries for evaluation.\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import classification_report"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Load Data**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load full training data set\n",
      "full_data = np.loadtxt(\"train.csv\", dtype = \"int\", delimiter = \",\", skiprows=1)\n",
      "feature_names = np.loadtxt(\"train.csv\", dtype = \"str\", delimiter = \",\")[0,:]\n",
      "feature_names = np.delete(feature_names, [0,55]) # Remove ID and output variable to match data set\n",
      "\n",
      "# Split into data and labels\n",
      "full_data_labels = full_data[:,full_data.shape[1]-1]\n",
      "full_data = full_data[:,:full_data.shape[1]-1]\n",
      "full_data = np.delete(full_data, 0, 1)  # Delete id to prevent use as feature\n",
      "\n",
      "print (\"full data shape: \", full_data.shape)\n",
      "print (\"full label shape:\", full_data_labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "full data shape:  (15120, 54)\n",
        "full label shape: (15120,)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Define and Review Train/Dev Data**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Split into smaller training set and a dev set for us to use\n",
      "# Shuffle the input so that we get a random subset in training vs dev\n",
      "# Test set provided separately from kaggle where we do not know the labels\n",
      "np.random.seed(58230)\n",
      "shuffle = np.random.permutation(np.arange(full_data.shape[0]))\n",
      "full_data, full_data_labels = full_data[shuffle], full_data_labels[shuffle]\n",
      "\n",
      "train_data, train_labels = full_data[:14120], full_data_labels[:14120]\n",
      "dev_data, dev_labels = full_data[14120:], full_data_labels[14120:]\n",
      "\n",
      "print (\"\\ntrain data shape: \", train_data.shape)\n",
      "print (\"train label shape:\", train_labels.shape)\n",
      "print (\"\\ndev data shape: \", dev_data.shape)\n",
      "print (\"dev label shape:\", dev_labels.shape)\n",
      "\n",
      "\n",
      "# Print some basic info looking at a row of data\n",
      "print(\"\\nFeature names are:\")\n",
      "print(feature_names)\n",
      "\n",
      "print(\"\\nAn example row of training data:\")\n",
      "print(train_data[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train data shape:  (14120, 54)\n",
        "train label shape: (14120,)\n",
        "\n",
        "dev data shape:  (1000, 54)\n",
        "dev label shape: (1000,)\n",
        "\n",
        "Feature names are:\n",
        "['Elevation' 'Aspect' 'Slope' 'Horizontal_Distance_To_Hydrology'\n",
        " 'Vertical_Distance_To_Hydrology' 'Horizontal_Distance_To_Roadways'\n",
        " 'Hillshade_9am' 'Hillshade_Noon' 'Hillshade_3pm'\n",
        " 'Horizontal_Distance_To_Fire_Points' 'Wilderness_Area1'\n",
        " 'Wilderness_Area2' 'Wilderness_Area3' 'Wilderness_Area4' 'Soil_Type1'\n",
        " 'Soil_Type2' 'Soil_Type3' 'Soil_Type4' 'Soil_Type5' 'Soil_Type6'\n",
        " 'Soil_Type7' 'Soil_Type8' 'Soil_Type9' 'Soil_Type10' 'Soil_Type11'\n",
        " 'Soil_Type12' 'Soil_Type13' 'Soil_Type14' 'Soil_Type15' 'Soil_Type16'\n",
        " 'Soil_Type17' 'Soil_Type18' 'Soil_Type19' 'Soil_Type20' 'Soil_Type21'\n",
        " 'Soil_Type22' 'Soil_Type23' 'Soil_Type24' 'Soil_Type25' 'Soil_Type26'\n",
        " 'Soil_Type27' 'Soil_Type28' 'Soil_Type29' 'Soil_Type30' 'Soil_Type31'\n",
        " 'Soil_Type32' 'Soil_Type33' 'Soil_Type34' 'Soil_Type35' 'Soil_Type36'\n",
        " 'Soil_Type37' 'Soil_Type38' 'Soil_Type39' 'Soil_Type40']\n",
        "\n",
        "An example row of training data:\n",
        "[2801   60   27  335  122  361  229  172   59 1900    1    0    0    0\n",
        "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
        "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
        "    1    0    0    0    0    0    0    0    0    0    0    0]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Preprocessing**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Confirm features with 0 variation\n",
      "print(\"For feature %s there are %d unique values in the training data\" % (feature_names[20], np.unique(train_data[:,20]).shape[0]))\n",
      "print(\"For feature %s there are %d unique values in the training data\" % (feature_names[21], np.unique(train_data[:,21]).shape[0]))\n",
      "print(\"For feature %s there are %d unique values in the training data\" % (feature_names[28], np.unique(train_data[:,28]).shape[0]))\n",
      "\n",
      "# Remove those features - Note: only run this section once\n",
      "train_data = np.delete(train_data, [20,21,28], 1)\n",
      "print (\"\\ntrain data shape: \", train_data.shape)\n",
      "\n",
      "dev_data = np.delete(dev_data, [20,21,28], 1)\n",
      "print (\"\\ndev data shape: \", dev_data.shape)\n",
      "\n",
      "feature_names = np.delete(feature_names, [20,21,28])\n",
      "print(\"\\nFeature names are:\")\n",
      "print(feature_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "For feature Soil_Type7 there are 1 unique values in the training data\n",
        "For feature Soil_Type8 there are 1 unique values in the training data\n",
        "For feature Soil_Type15 there are 1 unique values in the training data\n",
        "\n",
        "train data shape:  (14120, 51)\n",
        "\n",
        "dev data shape:  (1000, 51)\n",
        "\n",
        "Feature names are:\n",
        "['Elevation' 'Aspect' 'Slope' 'Horizontal_Distance_To_Hydrology'\n",
        " 'Vertical_Distance_To_Hydrology' 'Horizontal_Distance_To_Roadways'\n",
        " 'Hillshade_9am' 'Hillshade_Noon' 'Hillshade_3pm'\n",
        " 'Horizontal_Distance_To_Fire_Points' 'Wilderness_Area1'\n",
        " 'Wilderness_Area2' 'Wilderness_Area3' 'Wilderness_Area4' 'Soil_Type1'\n",
        " 'Soil_Type2' 'Soil_Type3' 'Soil_Type4' 'Soil_Type5' 'Soil_Type6'\n",
        " 'Soil_Type9' 'Soil_Type10' 'Soil_Type11' 'Soil_Type12' 'Soil_Type13'\n",
        " 'Soil_Type14' 'Soil_Type16' 'Soil_Type17' 'Soil_Type18' 'Soil_Type19'\n",
        " 'Soil_Type20' 'Soil_Type21' 'Soil_Type22' 'Soil_Type23' 'Soil_Type24'\n",
        " 'Soil_Type25' 'Soil_Type26' 'Soil_Type27' 'Soil_Type28' 'Soil_Type29'\n",
        " 'Soil_Type30' 'Soil_Type31' 'Soil_Type32' 'Soil_Type33' 'Soil_Type34'\n",
        " 'Soil_Type35' 'Soil_Type36' 'Soil_Type37' 'Soil_Type38' 'Soil_Type39'\n",
        " 'Soil_Type40']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check whether binary features can be combined into multinomial features\n",
      "\n",
      "# Wilderness area features are unique - observation will be in only one wilderness area\n",
      "print(feature_names[10:14])\n",
      "print(\"Number of unique sum of wilderness areas: \", np.unique(np.sum(train_data[:,10:14], axis=1)))\n",
      "print(\"Sum across all observations of wilderness areas: \", np.sum(train_data[:,10:14]))\n",
      "\n",
      "# Soil type area features are unique - observation will contain only one soil type\n",
      "print('\\n')\n",
      "print(feature_names[14:51])\n",
      "print(\"Number of unique sum of soil types: \", np.unique(np.sum(train_data[:,14:51], axis=1)))\n",
      "print(\"Sum across all observations of soil types: \", np.sum(train_data[:,14:51]))\n",
      "\n",
      "# Create new multinomial feature for wilderness area and soil type\n",
      "# Note that this is creating a new data set to avoid altering results already explored with the binary variables\n",
      "w = np.reshape(np.array([1,2,3,4]), (4,1))\n",
      "s = np.reshape(np.array([1,2,3,4,5,6,9,10,11,12,13,14,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40]), (37,1))\n",
      "\n",
      "binary_combo_train_data = np.hstack((train_data[:,0:10],np.dot(train_data[:,10:14],w),np.dot(train_data[:,14:51],s)))\n",
      "binary_combo_dev_data = np.hstack((dev_data[:,0:10],np.dot(dev_data[:,10:14],w),np.dot(dev_data[:,14:51],s)))\n",
      "binary_combo_feature_names = np.append(feature_names[:10],np.array(['WildernessArea','SoilType']))\n",
      "\n",
      "print (\"\\ntrain data shape: \", binary_combo_train_data.shape)\n",
      "print (\"dev data shape: \", binary_combo_dev_data.shape)\n",
      "\n",
      "print(\"Feature names are:\")\n",
      "print(binary_combo_feature_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Wilderness_Area1' 'Wilderness_Area2' 'Wilderness_Area3'\n",
        " 'Wilderness_Area4']\n",
        "Number of unique sum of wilderness areas:  [1]\n",
        "Sum across all observations of wilderness areas:  14120\n",
        "\n",
        "\n",
        "['Soil_Type1' 'Soil_Type2' 'Soil_Type3' 'Soil_Type4' 'Soil_Type5'\n",
        " 'Soil_Type6' 'Soil_Type9' 'Soil_Type10' 'Soil_Type11' 'Soil_Type12'\n",
        " 'Soil_Type13' 'Soil_Type14' 'Soil_Type16' 'Soil_Type17' 'Soil_Type18'\n",
        " 'Soil_Type19' 'Soil_Type20' 'Soil_Type21' 'Soil_Type22' 'Soil_Type23'\n",
        " 'Soil_Type24' 'Soil_Type25' 'Soil_Type26' 'Soil_Type27' 'Soil_Type28'\n",
        " 'Soil_Type29' 'Soil_Type30' 'Soil_Type31' 'Soil_Type32' 'Soil_Type33'\n",
        " 'Soil_Type34' 'Soil_Type35' 'Soil_Type36' 'Soil_Type37' 'Soil_Type38'\n",
        " 'Soil_Type39' 'Soil_Type40']\n",
        "Number of unique sum of soil types:  [1]\n",
        "Sum across all observations of soil types:  14120\n",
        "\n",
        "train data shape:  (14120, 12)\n",
        "dev data shape:  (1000, 12)\n",
        "Feature names are:\n",
        "['Elevation' 'Aspect' 'Slope' 'Horizontal_Distance_To_Hydrology'\n",
        " 'Vertical_Distance_To_Hydrology' 'Horizontal_Distance_To_Roadways'\n",
        " 'Hillshade_9am' 'Hillshade_Noon' 'Hillshade_3pm'\n",
        " 'Horizontal_Distance_To_Fire_Points' 'WildernessArea' 'SoilType']\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Scaling\n",
      "def my_scaler(data):    \n",
      "    scaler = preprocessing.StandardScaler()\n",
      "    continuous = scaler.fit_transform(data[:,:10])\n",
      "    binary = data[:,10:]\n",
      "    return np.concatenate((continuous, binary),axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Feature selection\n",
      "def my_featureselection(num_features, fit_data, fit_labels, transform_data):\n",
      "    selection = SelectKBest(k=num_features)\n",
      "    top_train = selection.fit_transform(fit_data,fit_labels)\n",
      "    top_dev = selection.transform(transform_data)\n",
      "    return [top_train, top_dev]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set up scaling of all original data, top 25 variables only, top 25 variables of scaled data, and scaling of top 25 variables\n",
      "scaled_train_data = my_scaler(train_data)\n",
      "scaled_dev_data = my_scaler(dev_data)\n",
      "top25_train_data,top25_dev_data = my_featureselection(25,train_data,train_labels,dev_data)\n",
      "top25_scaled_train_data,top25_scaled_dev_data = my_featureselection(25,scaled_train_data,train_labels,scaled_dev_data)\n",
      "scaled_top25_train_data = my_scaler(my_featureselection(25,train_data,train_labels,dev_data)[0])\n",
      "scaled_top25_dev_data = my_scaler(my_featureselection(25,train_data,train_labels,dev_data)[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/__init__.py:127: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
        "  if np.issubdtype(mask.dtype, np.int):\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n",
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
        "  warnings.warn(msg, DataConversionWarning)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define Model Assessment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def assess_model(model,train_data,train_labels,dev_data, replace_sigma=0, sigma_value1=0, sigma_value2=0):\n",
      "    model = model\n",
      "    model.fit(train_data,train_labels)\n",
      "    \n",
      "    if replace_sigma==1:       \n",
      "        # Set up new sigma array\n",
      "        new_sigma = model.sigma_\n",
      "        \n",
      "        # For each binary feature, reset its sigma value to the quantity provided\n",
      "        for i in range(train_data.shape[1]):\n",
      "            if np.unique(train_data[:,i]).shape[0]==2:\n",
      "                new_sigma[:,i] = sigma_value1\n",
      "        \n",
      "        # Replace sigma array for the model\n",
      "        model.sigma_ = new_sigma\n",
      "        \n",
      "    if replace_sigma==2:       \n",
      "        # Set up new sigma array\n",
      "        new_sigma = model.sigma_\n",
      "        \n",
      "        # For the multinomial feature, reset their sigma value to the quantity provided\n",
      "        # Assumes no other features have the same number of unique values. Confirmed this for initial continuous variables\n",
      "        # Takes first value provided for wilderness area, second for soil type\n",
      "        for i in range(train_data.shape[1]):\n",
      "            if np.unique(train_data[:,i]).shape[0]==4:\n",
      "                new_sigma[:,i] = sigma_value1\n",
      "            if np.unique(train_data[:,i]).shape[0]==37:\n",
      "                new_sigma[:,i] = sigma_value2\n",
      "        \n",
      "        # Replace sigma array for the model\n",
      "        model.sigma_ = new_sigma\n",
      "        \n",
      "    dev_preds = model.predict(dev_data)\n",
      "    \n",
      "    accuracy = metrics.accuracy_score(dev_labels,dev_preds)\n",
      "    f1score = metrics.f1_score(dev_labels,dev_preds,average='weighted')\n",
      "    confusion = confusion_matrix(dev_labels,dev_preds) \n",
      "    report = classification_report(dev_labels,dev_preds)\n",
      "    \n",
      "    print('Accuracy: ', accuracy)\n",
      "    print('F1 Score: ', f1score)\n",
      "    print('Confusion Matrix: \\n', confusion)\n",
      "    print('Classification Report: \\n',report)\n",
      "    \n",
      "    return [accuracy,f1score,confusion,report]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Gaussian Naive Bayes**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, let us test the default parameters on the data sets that were set up in the preprocessing section. We find that using all variables in the unscaled data set gives us the highest accuracy. We believe the scaling hurts because the couple of continuous variables have the most variation, and emphasizing that is helpful in contrast to the binary variables. Additionally, it is likely that the Gaussian model is a poor fit for the binary data points and may not be best utilizing that information."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_results = assess_model(GaussianNB(),train_data,train_labels,dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.613\n",
        "F1 Score:  0.5626726288786668\n",
        "Confusion Matrix: \n",
        " [[111   6   1   0  15   0  13]\n",
        " [ 56  14  12   0  31   0   0]\n",
        " [  0   0 121  33   3   0   0]\n",
        " [  0   0   8 126   0   0   0]\n",
        " [ 18   1  20   0 101   4   0]\n",
        " [  2   0 103  26  10  15   0]\n",
        " [ 25   0   0   0   0   0 125]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.52      0.76      0.62       146\n",
        "          2       0.67      0.12      0.21       113\n",
        "          3       0.46      0.77      0.57       157\n",
        "          4       0.68      0.94      0.79       134\n",
        "          5       0.63      0.70      0.66       144\n",
        "          6       0.79      0.10      0.17       156\n",
        "          7       0.91      0.83      0.87       150\n",
        "\n",
        "avg / total       0.66      0.61      0.56      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_results = assess_model(GaussianNB(),scaled_train_data,train_labels,scaled_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.487\n",
        "F1 Score:  0.405022884621059\n",
        "Confusion Matrix: \n",
        " [[ 27   0   2   0  34   3  80]\n",
        " [ 13   1   9   4  51   1  34]\n",
        " [  0   0  61  95   1   0   0]\n",
        " [  0   0   0 134   0   0   0]\n",
        " [  0   0  39   0 103   2   0]\n",
        " [  0   0  56  80   3  16   1]\n",
        " [  2   0   0   0   3   0 145]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.64      0.18      0.29       146\n",
        "          2       1.00      0.01      0.02       113\n",
        "          3       0.37      0.39      0.38       157\n",
        "          4       0.43      1.00      0.60       134\n",
        "          5       0.53      0.72      0.61       144\n",
        "          6       0.73      0.10      0.18       156\n",
        "          7       0.56      0.97      0.71       150\n",
        "\n",
        "avg / total       0.59      0.49      0.41      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_results = assess_model(GaussianNB(),top25_train_data,train_labels,top25_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.605\n",
        "F1 Score:  0.5761239600398651\n",
        "Confusion Matrix: \n",
        " [[ 56  10   4   0  23   5  48]\n",
        " [ 15  21   6   0  45  14  12]\n",
        " [  0   0  69  41   5  42   0]\n",
        " [  0   0   0 131   0   3   0]\n",
        " [  1   4   8   0 104  27   0]\n",
        " [  0   0  24  43   6  83   0]\n",
        " [  9   0   0   0   0   0 141]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.69      0.38      0.49       146\n",
        "          2       0.60      0.19      0.28       113\n",
        "          3       0.62      0.44      0.51       157\n",
        "          4       0.61      0.98      0.75       134\n",
        "          5       0.57      0.72      0.64       144\n",
        "          6       0.48      0.53      0.50       156\n",
        "          7       0.70      0.94      0.80       150\n",
        "\n",
        "avg / total       0.61      0.60      0.58      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_results = assess_model(GaussianNB(),scaled_top25_train_data,train_labels,scaled_top25_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.308\n",
        "F1 Score:  0.23165652808734\n",
        "Confusion Matrix: \n",
        " [[ 17   3   0   0 101   0  25]\n",
        " [  1  14   0   0  97   0   1]\n",
        " [  0  98   0   0  59   0   0]\n",
        " [  0 134   0   0   0   0   0]\n",
        " [  0   0   0   0 144   0   0]\n",
        " [  0  83   0   0  73   0   0]\n",
        " [  2   0   0   0  15   0 133]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.85      0.12      0.20       146\n",
        "          2       0.04      0.12      0.06       113\n",
        "          3       0.00      0.00      0.00       157\n",
        "          4       0.00      0.00      0.00       134\n",
        "          5       0.29      1.00      0.45       144\n",
        "          6       0.00      0.00      0.00       156\n",
        "          7       0.84      0.89      0.86       150\n",
        "\n",
        "avg / total       0.30      0.31      0.23      1000\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n",
        "/usr/lib/python3/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_results = assess_model(GaussianNB(),top25_scaled_train_data,train_labels,top25_scaled_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.438\n",
        "F1 Score:  0.376677939473285\n",
        "Confusion Matrix: \n",
        " [[ 17   3  48   0  57   0  21]\n",
        " [  1   9  44   4  54   0   1]\n",
        " [  0   0  60  95   2   0   0]\n",
        " [  0   0   0 134   0   0   0]\n",
        " [  0   0  57   0  85   2   0]\n",
        " [  0   0  63  82   5   6   0]\n",
        " [  2   0  14   0   7   0 127]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.85      0.12      0.20       146\n",
        "          2       0.75      0.08      0.14       113\n",
        "          3       0.21      0.38      0.27       157\n",
        "          4       0.43      1.00      0.60       134\n",
        "          5       0.40      0.59      0.48       144\n",
        "          6       0.75      0.04      0.07       156\n",
        "          7       0.85      0.85      0.85       150\n",
        "\n",
        "avg / total       0.60      0.44      0.38      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given our findings above, we investigated only using the continuous variables and removing all binary variables. We find that this has only a minor impact on accuracy (0.613 to 0.603), and now the scaling does not drastically change the results (0.603 to 0.601). Scaling does not help because the Gaussian model already takes into account the mean and standard deviation of each variable. Limiting to continuous variables tends to help in classifying type 6 (previously primarily misclassified as type 3), but hurts our classification of type 3 (now many misclassified as type 6). Type 2 continues to often be mistaken for type 1 and type 5."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cont_train = train_data[:,:10]\n",
      "cont_dev = dev_data[:,:10]\n",
      "scaled_cont_train = scaled_train_data[:,:10]\n",
      "scaled_cont_dev = scaled_dev_data[:,:10]\n",
      "\n",
      "model_results = assess_model(GaussianNB(),cont_train,train_labels,cont_dev)\n",
      "model_results = assess_model(GaussianNB(),scaled_cont_train,train_labels,scaled_cont_dev)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.603\n",
        "F1 Score:  0.599373216953498\n",
        "Confusion Matrix: \n",
        " [[ 83  26   2   0  11   1  23]\n",
        " [ 31  42   5   0  24   8   3]\n",
        " [  0   7  66  24  14  46   0]\n",
        " [  0   0   9 108   0  17   0]\n",
        " [  0  30   0   0  95  19   0]\n",
        " [  0   9  34  24   8  81   0]\n",
        " [ 19   0   3   0   0   0 128]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.62      0.57      0.59       146\n",
        "          2       0.37      0.37      0.37       113\n",
        "          3       0.55      0.42      0.48       157\n",
        "          4       0.69      0.81      0.74       134\n",
        "          5       0.62      0.66      0.64       144\n",
        "          6       0.47      0.52      0.49       156\n",
        "          7       0.83      0.85      0.84       150\n",
        "\n",
        "avg / total       0.60      0.60      0.60      1000\n",
        "\n",
        "Accuracy: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.601\n",
        "F1 Score:  0.5973832727207581\n",
        "Confusion Matrix: \n",
        " [[ 84  26   2   0  11   1  22]\n",
        " [ 30  43   5   0  26   6   3]\n",
        " [  0   8  64  23  14  48   0]\n",
        " [  0   0  10 108   0  16   0]\n",
        " [  0  31   0   0  98  15   0]\n",
        " [  0  10  37  23   9  77   0]\n",
        " [ 20   0   3   0   0   0 127]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.63      0.58      0.60       146\n",
        "          2       0.36      0.38      0.37       113\n",
        "          3       0.53      0.41      0.46       157\n",
        "          4       0.70      0.81      0.75       134\n",
        "          5       0.62      0.68      0.65       144\n",
        "          6       0.47      0.49      0.48       156\n",
        "          7       0.84      0.85      0.84       150\n",
        "\n",
        "avg / total       0.60      0.60      0.60      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible that the binary values are not being represented by the Gaussian model well due to standard deviation values. Investigate sigma values, then run Gaussian model with correction for sigma values. Note that we will only run this on unscaled data since the scaling is not needed with this type of model. This increases our accuracy to 0.664 for the model run on the top 25 variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Investigate sigma values for binary features in the model trained on the full unscaled data set\n",
      "\n",
      "# Create the model\n",
      "model = GaussianNB()\n",
      "model.fit(train_data,train_labels)\n",
      "sigma = model.sigma_\n",
      "\n",
      "# For sigma, notice that many values for binary data are very small\n",
      "# There is very little differentiation across class/features\n",
      "# But the standard deviation across all features for all classes is larger\n",
      "print('Example values of sigma for binary features:')\n",
      "print(sigma[0,10:])\n",
      "print('\\nMax sigma value for binary features:')\n",
      "print(round(np.max(sigma[:,10:]),3))\n",
      "print('\\nStandard deviation of binary sigma values:')\n",
      "print(round(np.std(sigma[:,10:]),3))\n",
      "print('Standard deviation across all classes and binary features:')\n",
      "print(round(np.std(train_data[:,10:]),3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Example values of sigma for binary features:\n",
        "[0.25173699 0.07863293 0.24552896 0.00176164 0.00176164 0.00176164\n",
        " 0.00176164 0.0042381  0.00176164 0.00176164 0.00225792 0.00571806\n",
        " 0.0037438  0.01207993 0.00915404 0.00176164 0.00522523 0.00275371\n",
        " 0.00176164 0.00866466 0.02027357 0.00571806 0.11345447 0.1466363\n",
        " 0.05779444 0.00176164 0.00522523 0.00522523 0.00176164 0.15576628\n",
        " 0.0380735  0.05073364 0.09555223 0.07904588 0.00176164 0.003249\n",
        " 0.00176164 0.00176164 0.0380735  0.0380735  0.02408009]\n",
        "\n",
        "Max sigma value for binary features:\n",
        "0.252\n",
        "\n",
        "Standard deviation of binary sigma values:\n",
        "0.061\n",
        "Standard deviation across all classes and binary features:\n",
        "0.215\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate standard deviation of all binary features in training data (regardless of which are in the model)\n",
      "# This is across all observations / classes\n",
      "sd_data = np.std(train_data[:,10:])\n",
      "        \n",
      "model_results = assess_model(GaussianNB(),train_data,train_labels,dev_data,1,sd_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.655\n",
        "F1 Score:  0.6468727935576123\n",
        "Confusion Matrix: \n",
        " [[ 85  23   2   0  12   1  23]\n",
        " [ 29  50   4   0  23   6   1]\n",
        " [  0   4  65  22  19  47   0]\n",
        " [  0   0   4 118   0  12   0]\n",
        " [  2  18   0   0 112  12   0]\n",
        " [  0   4  32  16  12  92   0]\n",
        " [ 15   0   2   0   0   0 133]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.65      0.58      0.61       146\n",
        "          2       0.51      0.44      0.47       113\n",
        "          3       0.60      0.41      0.49       157\n",
        "          4       0.76      0.88      0.81       134\n",
        "          5       0.63      0.78      0.70       144\n",
        "          6       0.54      0.59      0.56       156\n",
        "          7       0.85      0.89      0.87       150\n",
        "\n",
        "avg / total       0.65      0.66      0.65      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_results = assess_model(GaussianNB(),top25_train_data,train_labels,top25_dev_data,1,sd_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.664\n",
        "F1 Score:  0.6490972408908385\n",
        "Confusion Matrix: \n",
        " [[ 80  24   2   0  11   1  28]\n",
        " [ 30  46   2   0  25   8   2]\n",
        " [  0   3  67  22  21  44   0]\n",
        " [  0   0   3 124   0   7   0]\n",
        " [  1   9   0   0 125   9   0]\n",
        " [  0   0  32  25  18  81   0]\n",
        " [  9   0   0   0   0   0 141]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.67      0.55      0.60       146\n",
        "          2       0.56      0.41      0.47       113\n",
        "          3       0.63      0.43      0.51       157\n",
        "          4       0.73      0.93      0.81       134\n",
        "          5       0.62      0.87      0.73       144\n",
        "          6       0.54      0.52      0.53       156\n",
        "          7       0.82      0.94      0.88       150\n",
        "\n",
        "avg / total       0.66      0.66      0.65      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We noticed that the binary features are really two multinomial features broken into many columns. Since NB treats each feature as independent, this might be giving more weight than intended to the wilderness area and soil type. We combined these together and want to test running the Gaussian model on the smaller number of variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_results = assess_model(GaussianNB(),binary_combo_train_data,train_labels,binary_combo_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.634\n",
        "F1 Score:  0.6213501486837545\n",
        "Confusion Matrix: \n",
        " [[ 90  20   0   0  10   2  24]\n",
        " [ 38  35   3   1  25   7   4]\n",
        " [  0   0  77  42   9  29   0]\n",
        " [  0   0   0 128   0   6   0]\n",
        " [  5  22   4   0  95  18   0]\n",
        " [  0   6  27  42   8  73   0]\n",
        " [ 14   0   0   0   0   0 136]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.61      0.62      0.61       146\n",
        "          2       0.42      0.31      0.36       113\n",
        "          3       0.69      0.49      0.57       157\n",
        "          4       0.60      0.96      0.74       134\n",
        "          5       0.65      0.66      0.65       144\n",
        "          6       0.54      0.47      0.50       156\n",
        "          7       0.83      0.91      0.87       150\n",
        "\n",
        "avg / total       0.63      0.63      0.62      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is an improvement over the initial Gaussian model on the full data set, but not as good as after inputting new sigma values for the binary variables. We will investigate the sigma values of the multinomial variables and try inputting new ones. This actually decreased accuracy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Investigate sigma values for multinomial features in the model trained on the full unscaled data set\n",
      "\n",
      "# Create the model\n",
      "model = GaussianNB()\n",
      "model.fit(binary_combo_train_data,train_labels)\n",
      "sigma = model.sigma_\n",
      "\n",
      "# For sigma, notice that the values for wilderness type are very small, while those for soil type are much larger and vary a lot\n",
      "# The standard deviation across the entire columns seem better\n",
      "print('Sigma for multinomial features:')\n",
      "print(sigma[:,10:])\n",
      "\n",
      "print('Standard deviation across all classes for each multinomial feature:')\n",
      "print(round(np.std(binary_combo_train_data[:,10]),3))\n",
      "print(round(np.std(binary_combo_train_data[:,11]),3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sigma for multinomial features:\n",
        "[[9.12375678e-01 3.65809183e+01]\n",
        " [9.86880525e-01 6.82962839e+01]\n",
        " [2.41741664e-01 1.52238496e+01]\n",
        " [1.76164419e-03 3.14952284e+01]\n",
        " [9.63177461e-01 9.20685124e+01]\n",
        " [2.48525601e-01 4.38803926e+01]\n",
        " [7.50797559e-01 2.27007651e+01]]\n",
        "Standard deviation across all classes for each multinomial feature:\n",
        "1.124\n",
        "12.632\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate standard deviation of multinomial features in training data\n",
      "# This is across all observations\n",
      "sd_data_w = np.std(binary_combo_train_data[:,10])\n",
      "sd_data_s = np.std(binary_combo_train_data[:,11])\n",
      "        \n",
      "model_results = assess_model(GaussianNB(),binary_combo_train_data,train_labels,binary_combo_dev_data,2,sd_data_w,sd_data_s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.6\n",
        "F1 Score:  0.5953981336206361\n",
        "Confusion Matrix: \n",
        " [[ 84  28   0   0  10   1  23]\n",
        " [ 45  33   3   0  16  12   4]\n",
        " [  0   0  81  23   3  50   0]\n",
        " [  0   0  10 106   0  18   0]\n",
        " [ 15  19  12   0  78  20   0]\n",
        " [  1   9  41  22   2  81   0]\n",
        " [ 13   0   0   0   0   0 137]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.53      0.58      0.55       146\n",
        "          2       0.37      0.29      0.33       113\n",
        "          3       0.55      0.52      0.53       157\n",
        "          4       0.70      0.79      0.74       134\n",
        "          5       0.72      0.54      0.62       144\n",
        "          6       0.45      0.52      0.48       156\n",
        "          7       0.84      0.91      0.87       150\n",
        "\n",
        "avg / total       0.60      0.60      0.60      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In summary, our best Gaussian NB resulted from limiting the data to the top 25 variables, not scaling the data, and updating the sigma values of the binary variables to the standard deviation across all binary variables. The accuracy was 0.664."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Combo - Gaussian NB and Bernoulli NB**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Even with modified sigma values, it is likely that Gaussian NB is not appropriately treating the binary values. One way to approach this is to combine a Gaussian and Bernoulli NB approach since the features are assumed to be independent in NB anyway. Here we will run the Gaussian model on the continuous variables, the Bernoulli model on the binary variables, and create a new data set of the output probabilities of each class. This will be a new data set of all continuous variables to use in a final Gaussian NB model. Unfortunately, this reduces the accuracy to 0.538."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Gaussian NB on continuous variables\n",
      "model_cont = GaussianNB()\n",
      "model_cont.fit(train_data[:,:10],train_labels)\n",
      "predict_cont_train = model_cont.predict_proba(train_data[:,:10])\n",
      "predict_cont_dev = model_cont.predict_proba(dev_data[:,:10])\n",
      "\n",
      "# Run Bernoulli NB on binary variables - first running grid search to identify best alpha\n",
      "model_binary = BernoulliNB()\n",
      "model_binary.fit(train_data[:,10:],train_labels)\n",
      "predict_binary_train = model_binary.predict_proba(train_data[:,10:])\n",
      "predict_binary_dev = model_binary.predict_proba(dev_data[:,10:])\n",
      "\n",
      "# Combine the predicted probabilities into a new data set\n",
      "new_train_data = np.hstack((predict_cont_train, predict_binary_train))\n",
      "new_dev_data = np.hstack((predict_cont_dev, predict_binary_dev))\n",
      "\n",
      "# Run a new Gaussian NB model on the new data set\n",
      "model_results = assess_model(GaussianNB(),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.538\n",
        "Accuracy 2:  0.538\n",
        "F1 Score:  0.4550021714153562\n",
        "Confusion Matrix: \n",
        " [[ 79   0   1   0  17   2  47]\n",
        " [ 52   0   4   4  45   3   5]\n",
        " [  0   0  43  91  18   5   0]\n",
        " [  0   0   1 133   0   0   0]\n",
        " [  8   0   8   0 126   2   0]\n",
        " [  1   0  47  77  21  10   0]\n",
        " [  1   2   0   0   0   0 147]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.56      0.54      0.55       146\n",
        "          2       0.00      0.00      0.00       113\n",
        "          3       0.41      0.27      0.33       157\n",
        "          4       0.44      0.99      0.61       134\n",
        "          5       0.56      0.88      0.68       144\n",
        "          6       0.45      0.06      0.11       156\n",
        "          7       0.74      0.98      0.84       150\n",
        "\n",
        "avg / total       0.47      0.54      0.46      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Combo - Gaussian NB and Multinomial NB**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try the same thing, but with the multinomial version of the binary variables. We get slightly worse results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run Gaussian NB on continuous variables\n",
      "model_cont = GaussianNB()\n",
      "model_cont.fit(train_data[:,:10],train_labels)\n",
      "predict_cont_train = model_cont.predict_proba(train_data[:,:10])\n",
      "predict_cont_dev = model_cont.predict_proba(dev_data[:,:10])\n",
      "\n",
      "# Run Multinomial NB on two multinomial variables\n",
      "model_multi = MultinomialNB()\n",
      "model_multi.fit(binary_combo_train_data[:,10:],train_labels)\n",
      "predict_multi_train = model_multi.predict_proba(binary_combo_train_data[:,10:])\n",
      "predict_multi_dev = model_multi.predict_proba(binary_combo_dev_data[:,10:])\n",
      "\n",
      "# Combine the predicted probabilities into a new data set\n",
      "new_train_data = np.hstack((predict_cont_train, predict_multi_train))\n",
      "new_dev_data = np.hstack((predict_cont_dev, predict_multi_dev))\n",
      "\n",
      "# Run a new Gaussian NB model on the new data set\n",
      "model_results = assess_model(GaussianNB(),new_train_data,train_labels,new_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.517\n",
        "F1 Score:  0.460296989904868\n",
        "Confusion Matrix: \n",
        " [[ 67   0   0   0  10   2  67]\n",
        " [ 66   1   1   5  26   6   8]\n",
        " [  0   0  38 105   4  10   0]\n",
        " [  0   0   0 127   0   7   0]\n",
        " [ 18   1   7   0 104  14   0]\n",
        " [  1   2  11 101   8  33   0]\n",
        " [  0   3   0   0   0   0 147]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.44      0.46      0.45       146\n",
        "          2       0.14      0.01      0.02       113\n",
        "          3       0.67      0.24      0.36       157\n",
        "          4       0.38      0.95      0.54       134\n",
        "          5       0.68      0.72      0.70       144\n",
        "          6       0.46      0.21      0.29       156\n",
        "          7       0.66      0.98      0.79       150\n",
        "\n",
        "avg / total       0.50      0.52      0.46      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Multinomial NB**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another approach is to change the continuous variables into categorical variables. Here we follow that approach using the percentiles as bin boundaries (eg, create bins such that about 20% of the data falls into each bin for each variable). The resulting accuracy is 0.614, which is less than that achieved above with our Gaussian model with updated sigma values. This accuracy gets much worse when we use the multinomial data values instead of the binary ones for wilderness and soil type."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# first, for the data set including binary wilderness and soil variables\n",
      "\n",
      "# determine number of bins\n",
      "num_boundaries = 6\n",
      "\n",
      "# copy training data\n",
      "categorized_train_data = np.copy(train_data)\n",
      "categorized_dev_data = np.copy(dev_data)\n",
      "\n",
      "# for each non-binary variable, find decision boundaries and split the data into the appropriate number of bins\n",
      "for v in range(0,10):\n",
      "    boundaries=[]\n",
      "    for i in range(num_boundaries):\n",
      "        perc = np.percentile(train_data[:,v],(100/(num_boundaries-1))*i)\n",
      "        boundaries.append(perc)\n",
      "\n",
      "        if i==5:\n",
      "            categorized_train_data[:,v] = np.digitize(train_data[:,v],boundaries)\n",
      "            categorized_dev_data[:,v] = np.digitize(dev_data[:,v],boundaries)\n",
      "\n",
      "# Run a Multinomial NB model on the new categorized data, optimizing alpha\n",
      "params = {'alpha': [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
      "model_search = GridSearchCV(MultinomialNB(),param_grid=params)\n",
      "model_search.fit(categorized_train_data,train_labels)\n",
      "print(model_search.best_params_)\n",
      "print(model_search.best_score_)\n",
      "\n",
      "print('\\n')\n",
      "model_results = assess_model(MultinomialNB(alpha=0.1),categorized_train_data,train_labels,categorized_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3/dist-packages/sklearn/naive_bayes.py:664: RuntimeWarning: divide by zero encountered in log\n",
        "  self.feature_log_prob_ = (np.log(smoothed_fc)\n",
        "/usr/lib/python3/dist-packages/sklearn/naive_bayes.py:664: RuntimeWarning: divide by zero encountered in log\n",
        "  self.feature_log_prob_ = (np.log(smoothed_fc)\n",
        "/usr/lib/python3/dist-packages/sklearn/naive_bayes.py:664: RuntimeWarning: divide by zero encountered in log\n",
        "  self.feature_log_prob_ = (np.log(smoothed_fc)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'alpha': 0.1}\n",
        "0.611756373937677\n",
        "\n",
        "\n",
        "Accuracy:  0.614\n",
        "F1 Score:  0.6163924932655708\n",
        "Confusion Matrix: \n",
        " [[ 72  44   0   0  18   2  10]\n",
        " [ 24  57   2   0  23   7   0]\n",
        " [  0   0  70  15  11  61   0]\n",
        " [  0   0  18 108   0   8   0]\n",
        " [ 18  17  12   0  91   6   0]\n",
        " [  2   2  39   8  13  92   0]\n",
        " [ 14  10   0   0   2   0 124]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.55      0.49      0.52       146\n",
        "          2       0.44      0.50      0.47       113\n",
        "          3       0.50      0.45      0.47       157\n",
        "          4       0.82      0.81      0.82       134\n",
        "          5       0.58      0.63      0.60       144\n",
        "          6       0.52      0.59      0.55       156\n",
        "          7       0.93      0.83      0.87       150\n",
        "\n",
        "avg / total       0.62      0.61      0.62      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# second, for the data set with multinomial wilderness and soil type\n",
      "\n",
      "# determine number of bins\n",
      "num_boundaries = 6\n",
      "\n",
      "# copy training data\n",
      "categorized_train_data = np.copy(binary_combo_train_data)\n",
      "categorized_dev_data = np.copy(binary_combo_dev_data)\n",
      "\n",
      "# for each continuous variable(first 10 columns), find decision boundaries and split the data into the appropriate number of bins\n",
      "for v in range(0,10):\n",
      "    boundaries=[]\n",
      "    for i in range(num_boundaries):\n",
      "        perc = np.percentile(binary_combo_train_data[:,v],(100/(num_boundaries-1))*i)\n",
      "        boundaries.append(perc)\n",
      "\n",
      "        if i==5:\n",
      "            categorized_train_data[:,v] = np.digitize(binary_combo_train_data[:,v],boundaries)\n",
      "            categorized_dev_data[:,v] = np.digitize(binary_combo_dev_data[:,v],boundaries)\n",
      "\n",
      "# Run a Multinomial NB model on the new categorized data, optimizing alpha\n",
      "params = {'alpha': [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
      "model_search = GridSearchCV(MultinomialNB(),param_grid=params)\n",
      "model_search.fit(categorized_train_data,train_labels)\n",
      "print(model_search.best_params_)\n",
      "print(model_search.best_score_)\n",
      "\n",
      "print('\\n')\n",
      "model_results = assess_model(MultinomialNB(alpha=2),categorized_train_data,train_labels,categorized_dev_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'alpha': 2.0}\n",
        "0.4509915014164306\n",
        "\n",
        "\n",
        "Accuracy:  0.443\n",
        "F1 Score:  0.43199877766513384\n",
        "Confusion Matrix: \n",
        " [[ 40  36   0   0  19   4  47]\n",
        " [ 26  29   4   1  10  14  29]\n",
        " [  0   0  70  17   2  68   0]\n",
        " [  0   0  28  67  22  17   0]\n",
        " [ 19  23  11   3  36  29  23]\n",
        " [  2   6  35  12  10  86   5]\n",
        " [ 28   4   0   0   3   0 115]]\n",
        "Classification Report: \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          1       0.35      0.27      0.31       146\n",
        "          2       0.30      0.26      0.27       113\n",
        "          3       0.47      0.45      0.46       157\n",
        "          4       0.67      0.50      0.57       134\n",
        "          5       0.35      0.25      0.29       144\n",
        "          6       0.39      0.55      0.46       156\n",
        "          7       0.53      0.77      0.62       150\n",
        "\n",
        "avg / total       0.44      0.44      0.43      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 95
    }
   ],
   "metadata": {}
  }
 ]
}