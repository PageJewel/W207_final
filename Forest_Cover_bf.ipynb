{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Cover Type: Baseline Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we are working on predicting the forest cover type among 7 classifications based on cartographic variables from the US Geological Survey and USFS for each 30 x 30 meter cell of forest.\n",
    "\n",
    "For more details, please see: https://www.kaggle.com/c/forest-cover-type-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Storm\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Storm\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# SK-Learn Libraries for feature tuning\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data. Note that kaggle has a separate file for test data which we will not load yet. Thus, we will split our training data into training and a dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data shape:  (15120, 54)\n",
      "full label shape: (15120,)\n",
      "\n",
      "train data shape:  (14120, 54)\n",
      "train label shape: (14120,)\n",
      "\n",
      "dev data shape:  (1000, 54)\n",
      "dev label shape: (1000,)\n",
      "\n",
      "Feature names are:\n",
      "['Elevation' 'Aspect' 'Slope' 'Horizontal_Distance_To_Hydrology'\n",
      " 'Vertical_Distance_To_Hydrology' 'Horizontal_Distance_To_Roadways'\n",
      " 'Hillshade_9am' 'Hillshade_Noon' 'Hillshade_3pm'\n",
      " 'Horizontal_Distance_To_Fire_Points' 'Wilderness_Area1' 'Wilderness_Area2'\n",
      " 'Wilderness_Area3' 'Wilderness_Area4' 'Soil_Type1' 'Soil_Type2'\n",
      " 'Soil_Type3' 'Soil_Type4' 'Soil_Type5' 'Soil_Type6' 'Soil_Type7'\n",
      " 'Soil_Type8' 'Soil_Type9' 'Soil_Type10' 'Soil_Type11' 'Soil_Type12'\n",
      " 'Soil_Type13' 'Soil_Type14' 'Soil_Type15' 'Soil_Type16' 'Soil_Type17'\n",
      " 'Soil_Type18' 'Soil_Type19' 'Soil_Type20' 'Soil_Type21' 'Soil_Type22'\n",
      " 'Soil_Type23' 'Soil_Type24' 'Soil_Type25' 'Soil_Type26' 'Soil_Type27'\n",
      " 'Soil_Type28' 'Soil_Type29' 'Soil_Type30' 'Soil_Type31' 'Soil_Type32'\n",
      " 'Soil_Type33' 'Soil_Type34' 'Soil_Type35' 'Soil_Type36' 'Soil_Type37'\n",
      " 'Soil_Type38' 'Soil_Type39' 'Soil_Type40']\n",
      "\n",
      "An example row of training data:\n",
      "[2801   60   27  335  122  361  229  172   59 1900    1    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Load full training data set\n",
    "full_data = np.loadtxt(\"train.csv\", dtype = \"int\", delimiter = \",\", skiprows=1)\n",
    "feature_names = np.loadtxt(\"train.csv\", dtype = \"str\", delimiter = \",\")[0,:]\n",
    "\n",
    "# Split into data and labels\n",
    "full_data_labels = full_data[:,full_data.shape[1]-1]\n",
    "full_data = full_data[:,:full_data.shape[1]-1]\n",
    "full_data = np.delete(full_data, 0, 1)  # Delete id to prevent use as feature\n",
    "print (\"full data shape: \", full_data.shape)\n",
    "print (\"full label shape:\", full_data_labels.shape)\n",
    "\n",
    "# Split into smaller training set and a dev set for us to use\n",
    "# Shuffle the input so that we get a random subset in training vs dev\n",
    "# Test set provided separately from kaggle where we do not know the labels\n",
    "np.random.seed(58230)\n",
    "shuffle = np.random.permutation(np.arange(full_data.shape[0]))\n",
    "full_data, full_data_labels = full_data[shuffle], full_data_labels[shuffle]\n",
    "\n",
    "train_data, train_labels = full_data[:14120], full_data_labels[:14120]\n",
    "dev_data, dev_labels = full_data[14120:], full_data_labels[14120:]\n",
    "\n",
    "print (\"\\ntrain data shape: \", train_data.shape)\n",
    "print (\"train label shape:\", train_labels.shape)\n",
    "print (\"\\ndev data shape: \", dev_data.shape)\n",
    "print (\"dev label shape:\", dev_labels.shape)\n",
    "\n",
    "\n",
    "# Print some basic info looking at a row of data\n",
    "print(\"\\nFeature names are:\")\n",
    "print(feature_names[1:-1])\n",
    "\n",
    "print(\"\\nAn example row of training data:\")\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Storm\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Storm\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [20 21 28] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\Storm\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "continuous = scaler.fit_transform(train_data[:, range(0, 10)])\n",
    "binary = train_data[:, range(10,54)]\n",
    "scaled_train_data = np.concatenate((continuous, binary), axis=1)\n",
    "\n",
    "con_dev = scaler.transform(dev_data[:, range(0, 10)])\n",
    "bin_dev = dev_data[:, range(10,54)]\n",
    "scaled_dev_data = np.concatenate((con_dev, bin_dev), axis=1)\n",
    "\n",
    "selection=SelectKBest(k=25)  # just checking univariate selection method first\n",
    "top_train=selection.fit_transform(scaled_train_data,train_labels)\n",
    "top_dev=selection.transform(scaled_dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a basic logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default logistic regression accuracy is 0.668\n"
     ]
    }
   ],
   "source": [
    "# Run logistic regression with default values and check accuracy\n",
    "model_log = LogisticRegression()\n",
    "model_log.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Default logistic regression accuracy is %1.3f\" % (model_log.score(dev_data,dev_labels)))\n",
    "#print(np.max(train_data,axis=0))\n",
    "#print(np.min(train_data,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a basic Gaussian Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default NB accuracy is 0.613\n"
     ]
    }
   ],
   "source": [
    "# Run NB with default values and check accuracy\n",
    "model_NB = GaussianNB()\n",
    "model_NB.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Default NB accuracy is %1.3f\" % (model_NB.score(dev_data,dev_labels)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a basic k-Nearest Neighbors model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default k-NN accuracy is 0.805\n"
     ]
    }
   ],
   "source": [
    "# Run k-NN with default values and check accuracy\n",
    "\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(train_data, train_labels)\n",
    "\n",
    "print(\"Default k-NN accuracy is %1.3f\" % (model_knn.score(dev_data,dev_labels)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 0.799\n",
      "Random Forest accuracy: 0.877\n",
      "Feature ranking:\n",
      "1. feature 0 (0.247243)\n",
      "2. feature 5 (0.094471)\n",
      "3. feature 9 (0.073010)\n",
      "4. feature 3 (0.062131)\n",
      "5. feature 4 (0.052283)\n",
      "6. feature 6 (0.049476)\n",
      "7. feature 1 (0.047296)\n",
      "8. feature 13 (0.047226)\n",
      "9. feature 8 (0.043487)\n",
      "10. feature 7 (0.042520)\n",
      "11. feature 2 (0.032757)\n",
      "12. feature 23 (0.023180)\n",
      "13. feature 51 (0.019865)\n",
      "14. feature 10 (0.019805)\n",
      "15. feature 16 (0.018405)\n",
      "16. feature 52 (0.016737)\n",
      "17. feature 12 (0.015766)\n",
      "18. feature 17 (0.012668)\n",
      "19. feature 53 (0.008711)\n",
      "20. feature 43 (0.006684)\n",
      "21. feature 15 (0.005958)\n",
      "22. feature 26 (0.005482)\n",
      "23. feature 30 (0.005301)\n",
      "24. feature 35 (0.004814)\n",
      "25. feature 45 (0.004690)\n",
      "26. feature 36 (0.004523)\n",
      "27. feature 42 (0.004354)\n",
      "28. feature 25 (0.004120)\n",
      "29. feature 11 (0.003458)\n",
      "30. feature 46 (0.003166)\n",
      "31. feature 24 (0.002922)\n",
      "32. feature 19 (0.002612)\n",
      "33. feature 48 (0.002242)\n",
      "34. feature 37 (0.002195)\n",
      "35. feature 44 (0.002129)\n",
      "36. feature 14 (0.001524)\n",
      "37. feature 33 (0.001496)\n",
      "38. feature 18 (0.001167)\n",
      "39. feature 29 (0.000872)\n",
      "40. feature 31 (0.000744)\n",
      "41. feature 27 (0.000493)\n",
      "42. feature 50 (0.000440)\n",
      "43. feature 39 (0.000432)\n",
      "44. feature 32 (0.000314)\n",
      "45. feature 47 (0.000268)\n",
      "46. feature 40 (0.000163)\n",
      "47. feature 34 (0.000139)\n",
      "48. feature 41 (0.000110)\n",
      "49. feature 49 (0.000074)\n",
      "50. feature 22 (0.000068)\n",
      "51. feature 38 (0.000013)\n",
      "52. feature 28 (0.000000)\n",
      "53. feature 21 (0.000000)\n",
      "54. feature 20 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", random_state=0)\n",
    "dt_clf.fit(train_data, train_labels)\n",
    "\n",
    "print('Decision Tree accuracy:', dt_clf.score(dev_data, dev_labels))\n",
    "\n",
    "rf_clf= RandomForestClassifier(n_estimators=250,max_features=10)\n",
    "rf_clf.fit(train_data, train_labels)\n",
    "\n",
    "print ('Random Forest accuracy:', rf_clf.score(dev_data, dev_labels))\n",
    "\n",
    "importances = rf_clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(dev_data.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN accuracy is 0.805\n"
     ]
    }
   ],
   "source": [
    "imp_train = train_data[:, (0,5,9,3,4,6,1,13,8)] #train knn on most important features in random forest model\n",
    "imp_dev = dev_data[:, (0,5,9,3,4,6,1,13,8)]\n",
    "knn2 = KNeighborsClassifier()\n",
    "knn2.fit(imp_train, train_labels)\n",
    "\n",
    "print(\"k-NN accuracy is %1.3f\" % (knn2.score(imp_dev,dev_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features 20,21, and 28 have zero variance and can be removed for further analysis\n",
    "subset_t_data = np.delete(train_data, 28, 1)\n",
    "subset_t_data = np.delete(subset_t_data, 21, 1)\n",
    "subset_t_data = np.delete(subset_t_data, 20, 1)\n",
    "subset_d_data = np.delete(dev_data, 28, 1)\n",
    "subset_d_data = np.delete(subset_d_data, 21, 1)\n",
    "subset_d_data = np.delete(subset_d_data, 20, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
